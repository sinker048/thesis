{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 載入package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from toolz import pipe, partial\n",
    "from os.path import join, splitext\n",
    "from mpmath import mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.optimize import minimize\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import block_diag\n",
    "from numpy.linalg import inv\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 整理資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sackmann_dir, tour='atp', keep_davis_cup=False):\n",
    "\n",
    "    all_csvs = glob(join(sackmann_dir, f'*{tour}_matches_doubles_????.csv'))\n",
    "    all_csvs = sorted(all_csvs, key=lambda x: int(splitext(x)[0][-4:]))\n",
    "\n",
    "    levels_to_drop = ['C', 'S']\n",
    "\n",
    "    if not keep_davis_cup:\n",
    "        levels_to_drop.append('D')\n",
    "\n",
    "    data = pipe(all_csvs,\n",
    "                # Read CSV\n",
    "                lambda y: map(partial(pd.read_csv, encoding=\"ISO=8859-1\",index_col=False), y),\n",
    "                # Drop NAs in important fields\n",
    "                lambda y: map(lambda x: x.dropna(\n",
    "                    subset=['winner1_name', 'loser1_name', 'winner2_name', 'loser2_name','score']),\n",
    "                    y),\n",
    "                # Drop retirements and walkovers\n",
    "                # TODO: Make this optional\n",
    "                lambda y: map(lambda x:\n",
    "                              x[~x['score'].astype(str).str.contains(\n",
    "                                'RET|W/O|DEF|nbsp|Def.')],\n",
    "                              y),\n",
    "                # Drop scores that appear truncated\n",
    "                lambda y: map(lambda x: x[\n",
    "                    x['score'].astype(str).str.len() > 4],\n",
    "                    y),\n",
    "                # Drop challengers and futures\n",
    "                # TODO: Make this optional too\n",
    "                lambda y: map(lambda x: x[\n",
    "                    ~x['tourney_level'].isin(levels_to_drop)],\n",
    "                    y),\n",
    "                pd.concat,\n",
    "                )\n",
    "\n",
    "    round_numbers = {\n",
    "        'R128': 1,\n",
    "        'RR': 1,\n",
    "        'R64': 2,\n",
    "        'R32': 3,\n",
    "        'R16': 4,\n",
    "        'QF': 5,\n",
    "        'SF': 6,\n",
    "        'F': 7\n",
    "    }\n",
    "\n",
    "    # Drop rounds outside this list\n",
    "    to_keep = data['round'].isin(round_numbers)\n",
    "    data = data[to_keep]\n",
    "\n",
    "    # Add a numerical round number\n",
    "    data['round_number'] = data['round'].replace(round_numbers)\n",
    "\n",
    "    # Add date information\n",
    "    data['tourney_date'] = pd.to_datetime(\n",
    "        data['tourney_date'].astype(int).astype(str), format='%Y%m%d')\n",
    "    data['year'] = data['tourney_date'].dt.year\n",
    "\n",
    "    # Sort by date and round and reset index\n",
    "    data = data.sort_values(['tourney_date', 'round_number'])\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    data['pts_won_serve_winner'] = data['w_1stWon'] + data['w_2ndWon']\n",
    "    data['pts_won_serve_loser'] = data['l_1stWon'] + data['l_2ndWon']\n",
    "\n",
    "    data['pts_played_serve_winner'] = data['w_svpt']\n",
    "    data['pts_played_serve_loser'] = data['l_svpt']\n",
    "\n",
    "    # Add serve % won\n",
    "    data['spw_winner'] = (data['w_1stWon'] + data['w_2ndWon']) / data['w_svpt']\n",
    "    data['spw_loser'] = (data['l_1stWon'] + data['l_2ndWon']) / data['l_svpt']\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "資料來自:https://github.com/JeffSackmann/tennis_atp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將雙打的資料整合起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data('tennis_atp-master/tennis_atp-master/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "收集2010年至2019年的比賽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['tourney_date'].dt.year >= 2010]\n",
    "to_use = data[data['tourney_date'].dt.year <= 2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將資料儲存至csv檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_use.to_csv(\"double.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = to_use[to_use['tourney_date'].dt.year <= 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = to_use[to_use['tourney_date'].dt.year > 2017]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各資料集的場地資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hard     5548\n",
       "Clay     3112\n",
       "Grass    1199\n",
       "Name: surface, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train['surface'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hard     1464\n",
       "Clay      767\n",
       "Grass     340\n",
       "Name: surface, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test['surface'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hard     7012\n",
       "Clay     3879\n",
       "Grass    1539\n",
       "Name: surface, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_use['surface'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "資料集的比賽場數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Dataset|Train|Test|Total|\n",
    "|---|---|---|---|\n",
    "|Begin|2010|2018|2010|\n",
    "|End|2017|2019|2019|\n",
    "|Hard|5548|1464|7012|\n",
    "|Clay|3112|767|3879|\n",
    "|Grass|1199|340|1539|\n",
    "|Total|9859|2571|12430|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_marks(marks):\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    encoded = encoder.fit_transform(marks)\n",
    "    oh = np.zeros((len(marks), len(encoder.classes_)))\n",
    "\n",
    "    oh[np.arange(len(marks)), encoded] = 1\n",
    "\n",
    "    return oh, encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = Train.reset_index()\n",
    "surface = encode_marks(Train['surface'])[0]\n",
    "winners = Train[['winner1_name','winner2_name']]\n",
    "losers = Train[['loser1_name','loser2_name']]\n",
    "Test = Test.reset_index()\n",
    "to_use = to_use.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_win_prob(mu_ik, mu_jk, c_ij):\n",
    "    '''\n",
    "    Calculate the win probability of p_ijk\n",
    "    '''\n",
    "    return np.array(mp.exp(mu_ik / c_ij)/(mp.exp(mu_ik / c_ij) + mp.exp(mu_jk / c_ij)), dtype = 'float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_discrepancy(s_ijk, mu_ik, mu_jk, c_ij):\n",
    "    '''\n",
    "    Calculate the discrepency between predicted and actual outcome.\n",
    "    '''\n",
    "    p_ijk = calculate_win_prob(mu_ik, mu_jk, c_ij)\n",
    "    return -s_ijk * np.log(p_ijk) - (1 - s_ijk) * np.log(1-p_ijk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mu'_{\\theta} = \\mu_{\\theta} - {H}^{-1}(\\mu_{\\theta})j(\\mu_{\\theta}) = \\mu_{\\theta} + \\delta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$j(\\mu_{\\theta}) =\\dfrac{1}{c_3} \\begin{bmatrix}\n",
    "0\\\\0\\\\s_{iq3} - \\dfrac{e^{\\mu_{i3}/c_3}}{e^{\\mu_{i3}/c_3}+e^{\\mu_{q3}/c_3}}\\\\0\\\\0\\\\1-s_{iq3}-\\dfrac{e^{\\mu_{q3}/c_3}}{e^{\\mu_{i3}/c_3}+e^{\\mu_{q3}/c_3}}\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H(\\mu_{\\theta})= - \\Sigma^{-1} + \\dfrac{1}{c^2_3}\n",
    "\\begin{bmatrix}\n",
    "0&0&0&0&0&0\\\\\n",
    "0&0&0&0&0&0\\\\\n",
    "0&0&-\\dfrac{e^{(\\mu_{i3}+\\mu_{q3})/c_3}}{(e^{\\mu_{i3}/c_3}+e^{\\mu_{q3}/c_3})^2}&0&0&\\dfrac{e^{(\\mu_{i3}+\\mu_{q3})/c_3}}{(e^{\\mu_{i3}/c_3}+e^{\\mu_{q3}/c_3})^2}\\\\\n",
    "0&0&0&0&0&0\\\\\n",
    "0&0&0&0&0&0\\\\\n",
    "0&0&\\dfrac{e^{(\\mu_{i3}+\\mu_{q3})/c_3}}{(e^{\\mu_{i3}/c_3}+e^{\\mu_{q3}/c_3})^2}&0&0&-\\dfrac{e^{(\\mu_{i3}+\\mu_{q3})/c_3}}{(e^{\\mu_{i3}/c_3}+e^{\\mu_{q3}/c_3})^2}\\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ratings(winners, losers, surface, beta, variance_1, variance_2, variance_3, rho_12, rho_13, rho_23):\n",
    "    '''\n",
    "    Calculate B-T model ratings.\n",
    "    Args:\n",
    "    winners: The array of winners for each of N contests, of shape [N, 2].\n",
    "    losers: The array of losers for each of N contests, of shape [N, 2].\n",
    "    surface: The array of surfaces for each of N contest, of shape [N, 3].\n",
    "    beta: The uncontral variances of the game\n",
    "    start_variance_1: The initial variance of the surface 1\n",
    "    start_variance_2: The initial variance of the surface 2\n",
    "    start_variance_3: The initial variance of the surface 3\n",
    "    rho_12: The initial correlation coefficient between surface 1 and surface 2\n",
    "    rho_13: The initial correlation coefficient between surface 1 and surface 3\n",
    "    rho_23: The initial correlation coefficient between surface 2 and surface 3\n",
    "    '''\n",
    "    prior_ratings = defaultdict(lambda :(np.array([[1500],[1500],[1500]],dtype = 'float64')))\n",
    "    \n",
    "    surface_variance = np.array([[variance_1, rho_12 * np.sqrt(variance_1*variance_2), rho_13 * np.sqrt(variance_1*variance_3)],\n",
    "                                [rho_12 * np.sqrt(variance_1*variance_2), variance_2, rho_23 * np.sqrt(variance_2*variance_3)],\n",
    "                                [rho_13 * np.sqrt(variance_1*variance_3), rho_23 * np.sqrt(variance_2*variance_3), variance_3]])\n",
    "    \n",
    "    rating_history = list()\n",
    "    total_discrepancy = 0\n",
    "    for game in np.arange(winners.shape[0]):\n",
    "        # current winners & losers\n",
    "        cur_winner_1, cur_winner_2 = winners['winner1_name'][game], winners['winner2_name'][game]\n",
    "        cur_loser_1, cur_loser_2 = losers['loser1_name'][game], losers['loser2_name'][game]\n",
    "        # current surface [1,3]\n",
    "        cur_surface = surface[game]\n",
    "        # current player\n",
    "        current_player = [cur_winner_1, cur_winner_2, cur_loser_1, cur_loser_2]\n",
    "        # check whether the player play\n",
    "        for player in current_player:\n",
    "            if player not in prior_ratings:\n",
    "                prior_ratings[player]\n",
    "        # save the prior rating\n",
    "        rating_history.append(copy.deepcopy(prior_ratings))\n",
    "        \n",
    "        new_rating = prior_ratings.copy()\n",
    "        # winners & loser rating\n",
    "        winner_1, winner_2 = new_rating[cur_winner_1], new_rating[cur_winner_2]\n",
    "        loser_1, loser_2 = new_rating[cur_loser_1], new_rating[cur_loser_2]\n",
    "        # team rating\n",
    "        winner = winner_1 + winner_2\n",
    "        loser = loser_1 + loser_2\n",
    "        # calculate sigma_k\n",
    "        sigma_k = cur_surface.dot(surface_variance).dot(cur_surface)        \n",
    "        # calculate c_ij        \n",
    "        c_ij = np.sqrt(sigma_k + sigma_k + 2 * beta **2)\n",
    "\n",
    "        # calculate p(x)\n",
    "        mu_ik = cur_surface.dot(winner)[0] # float\n",
    "        mu_jk = cur_surface.dot(loser)[0] #float\n",
    "\n",
    "        p_s = calculate_win_prob(mu_ik = mu_ik , mu_jk= mu_jk , c_ij= c_ij) # float\n",
    " \n",
    "        # calculate discrepancy\n",
    "        discrepancy = calculate_discrepancy(s_ijk= 1 , mu_ik = mu_ik, mu_jk= mu_jk, c_ij= c_ij)\n",
    "        # calculate total discrepancy\n",
    "        total_discrepancy += discrepancy\n",
    "        # calculate jacobian 6*1\n",
    "        jacobian = np.zeros((6,1))\n",
    "        jacobian[:3,:] = cur_surface.reshape((3,1)) - p_s * cur_surface.reshape((3,1))\n",
    "        jacobian[3:,:] = -(cur_surface.reshape((3,1)) - p_s * cur_surface.reshape((3,1)))\n",
    "        jacobian = 1/c_ij * jacobian\n",
    "\n",
    "        # calculate hessian matrix 6*6\n",
    "        Sigma = block_diag(surface_variance,surface_variance)\n",
    "        hes = np.zeros((6,6))\n",
    "        discre = p_s*(1-p_s) * cur_surface.reshape((3,1)).dot(cur_surface.reshape((1,3)))\n",
    "        hes[:3,:3] = - discre\n",
    "        hes[3:,:3] =  discre\n",
    "        hes[:3,3:] =  discre\n",
    "        hes[3:,3:] = - discre\n",
    "        hes = 1/(c_ij**2) * hes \n",
    "\n",
    "        hessian = - inv(Sigma) + hes\n",
    "\n",
    "        # update the team rating\n",
    "        \n",
    "        #winner -= inv(hessian).dot(jacobian)[:3,:]\n",
    "        #loser -= inv(hessian).dot(jacobian)[3:,:]\n",
    "        # update the winner player & loser player rating\n",
    "        new_rating[cur_winner_1] -= inv(hessian).dot(jacobian)[:3,:]/2\n",
    "        new_rating[cur_winner_2] -= inv(hessian).dot(jacobian)[:3,:]/2\n",
    "        \n",
    "        new_rating[cur_loser_1] -= inv(hessian).dot(jacobian)[3:,:]/2\n",
    "        new_rating[cur_loser_2] -= inv(hessian).dot(jacobian)[3:,:]/2\n",
    "        \n",
    "        # update prior rating\n",
    "        prior_ratings = new_rating\n",
    "        \n",
    "    return rating_history, total_discrepancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "my = calculate_ratings(winners, losers, surface, 3**2, 100**2, 100**2, 100**2, 0.5, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_parameter(\n",
    "    winners, \n",
    "    losers, \n",
    "    surface,\n",
    "    beta = 3 ** 2,\n",
    "    start_variance_1 = 10 ** 2, \n",
    "    start_variance_2 = 10 ** 2, \n",
    "    start_variance_3 = 10 ** 2, \n",
    "    start_rho_12 = 0.5, \n",
    "    start_rho_13 = 0.5, \n",
    "    start_rho_23 = 0.5,\n",
    "    verbose = True,\n",
    "    tolerance = 1e-2,\n",
    "):\n",
    "    '''Fits the parameters in B-T model.\n",
    "    Args:\n",
    "    winners: The array of winners for each of N contests, of shape [N, 2].\n",
    "    losers: The array of losers for each of N contests, of shape [N, 2].\n",
    "    surface: The array of surfaces for each of N contest, of shape [N, 3].\n",
    "    beta: The uncontral variances of the game\n",
    "    start_variance_1: The initial variance of the surface 1\n",
    "    start_variance_2: The initial variance of the surface 2\n",
    "    start_variance_3: The initial variance of the surface 3\n",
    "    rho_12: The initial correlation coefficient between surface 1 and surface 2\n",
    "    rho_13: The initial correlation coefficient between surface 1 and surface 3\n",
    "    rho_23: The initial correlation coefficient between surface 2 and surface 3\n",
    "    verbose: Whether or not to print the progress of the optimisation.\n",
    "    tolerance: The tolerance required for the optimisation to successfully terminate.\n",
    "    '''\n",
    "    def fun_to_minimize(theta):\n",
    "        # Constrain\n",
    "        variance_1, variance_2, variance_3, rho_12, rho_13, rho_23  = theta \n",
    "        _, discrepancy = calculate_ratings(winners, losers, surface, beta, variance_1, variance_2, variance_3, rho_12, rho_13, rho_23)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\n",
    "                f'variance_1: {variance_1:.2f}; '\n",
    "                f'variance_2: {variance_2:.2f}; '\n",
    "                f'variance_3: {variance_3:.2f}; '\n",
    "                f'rho_12: {rho_12:.4f}; '\n",
    "                f'rho_13: {rho_13:.4f}; '\n",
    "                f'rho_23: {rho_23:.4f}; '\n",
    "                f'discrepancy: {discrepancy:.3f}'\n",
    "            )\n",
    "        return discrepancy\n",
    "    \n",
    "    opt_result = minimize(fun_to_minimize,\n",
    "                          np.array([start_variance_1, start_variance_2, start_variance_3, start_rho_12, start_rho_13, start_rho_23]),\n",
    "                          method='Nelder-Mead',\n",
    "                          tol=tolerance,)\n",
    "    return (opt_result.success, {'variance_1':opt_result.x[0],\n",
    "                                 'variance_2':opt_result.x[1],\n",
    "                                 'variance_3':opt_result.x[2],\n",
    "                                 'rho_12':opt_result.x[3],\n",
    "                                 'rho_13':opt_result.x[4],\n",
    "                                 'rho_23':opt_result.x[5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance_1: 100.00; variance_2: 100.00; variance_3: 100.00; rho_12: 0.5000; rho_13: 0.5000; rho_23: 0.5000; discrepancy: 6325.760\n",
      "variance_1: 105.00; variance_2: 100.00; variance_3: 100.00; rho_12: 0.5000; rho_13: 0.5000; rho_23: 0.5000; discrepancy: 6326.461\n",
      "variance_1: 100.00; variance_2: 105.00; variance_3: 100.00; rho_12: 0.5000; rho_13: 0.5000; rho_23: 0.5000; discrepancy: 6325.370\n",
      "variance_1: 100.00; variance_2: 100.00; variance_3: 105.00; rho_12: 0.5000; rho_13: 0.5000; rho_23: 0.5000; discrepancy: 6327.476\n",
      "variance_1: 100.00; variance_2: 100.00; variance_3: 100.00; rho_12: 0.5250; rho_13: 0.5000; rho_23: 0.5000; discrepancy: 6325.525\n",
      "variance_1: 100.00; variance_2: 100.00; variance_3: 100.00; rho_12: 0.5000; rho_13: 0.5250; rho_23: 0.5000; discrepancy: 6324.837\n",
      "variance_1: 100.00; variance_2: 100.00; variance_3: 100.00; rho_12: 0.5000; rho_13: 0.5000; rho_23: 0.5250; discrepancy: 6324.955\n",
      "variance_1: 101.67; variance_2: 101.67; variance_3: 95.00; rho_12: 0.5083; rho_13: 0.5083; rho_23: 0.5083; discrepancy: 6323.410\n",
      "variance_1: 102.50; variance_2: 102.50; variance_3: 90.00; rho_12: 0.5125; rho_13: 0.5125; rho_23: 0.5125; discrepancy: 6321.298\n",
      "variance_1: 95.83; variance_2: 102.50; variance_3: 96.67; rho_12: 0.5125; rho_13: 0.5125; rho_23: 0.5125; discrepancy: 6322.778\n",
      "variance_1: 99.44; variance_2: 103.33; variance_3: 95.56; rho_12: 0.5167; rho_13: 0.5167; rho_23: 0.5167; discrepancy: 6322.506\n",
      "variance_1: 99.26; variance_2: 104.44; variance_3: 94.07; rho_12: 0.4889; rho_13: 0.5222; rho_23: 0.5222; discrepancy: 6321.743\n",
      "variance_1: 99.01; variance_2: 99.26; variance_3: 92.10; rho_12: 0.5102; rho_13: 0.5296; rho_23: 0.5296; discrepancy: 6320.665\n",
      "variance_1: 98.52; variance_2: 96.39; variance_3: 88.15; rho_12: 0.5153; rho_13: 0.5444; rho_23: 0.5444; discrepancy: 6318.306\n",
      "variance_1: 98.52; variance_2: 103.06; variance_3: 88.15; rho_12: 0.5153; rho_13: 0.5444; rho_23: 0.5111; discrepancy: 6318.863\n",
      "variance_1: 98.02; variance_2: 104.07; variance_3: 84.20; rho_12: 0.5204; rho_13: 0.5259; rho_23: 0.5398; discrepancy: 6316.876\n",
      "variance_1: 97.04; variance_2: 106.11; variance_3: 76.30; rho_12: 0.5306; rho_13: 0.5264; rho_23: 0.5597; discrepancy: 6312.761\n",
      "variance_1: 102.59; variance_2: 102.78; variance_3: 80.74; rho_12: 0.5139; rho_13: 0.5431; rho_23: 0.5431; discrepancy: 6315.602\n",
      "variance_1: 100.03; variance_2: 101.76; variance_3: 76.91; rho_12: 0.5088; rho_13: 0.5477; rho_23: 0.5477; discrepancy: 6313.504\n",
      "variance_1: 100.47; variance_2: 99.75; variance_3: 72.67; rho_12: 0.5432; rho_13: 0.5506; rho_23: 0.5506; discrepancy: 6311.608\n",
      "variance_1: 101.08; variance_2: 97.41; variance_3: 61.98; rho_12: 0.5704; rho_13: 0.5648; rho_23: 0.5648; discrepancy: 6306.531\n",
      "variance_1: 96.76; variance_2: 100.00; variance_3: 67.41; rho_12: 0.5389; rho_13: 0.5778; rho_23: 0.5778; discrepancy: 6307.074\n",
      "variance_1: 100.15; variance_2: 98.43; variance_3: 62.35; rho_12: 0.5440; rho_13: 0.5569; rho_23: 0.6014; discrepancy: 6305.600\n",
      "variance_1: 100.97; variance_2: 96.11; variance_3: 49.44; rho_12: 0.5583; rho_13: 0.5632; rho_23: 0.6465; discrepancy: 6299.333\n",
      "variance_1: 100.97; variance_2: 105.00; variance_3: 49.44; rho_12: 0.5583; rho_13: 0.5632; rho_23: 0.6021; discrepancy: 6300.095\n",
      "variance_1: 96.36; variance_2: 99.35; variance_3: 46.42; rho_12: 0.5745; rho_13: 0.5713; rho_23: 0.6231; discrepancy: 6297.822\n",
      "variance_1: 93.24; variance_2: 97.64; variance_3: 29.26; rho_12: 0.6049; rho_13: 0.5854; rho_23: 0.6632; discrepancy: 6294.592\n",
      "variance_1: 96.66; variance_2: 99.00; variance_3: 34.36; rho_12: 0.6117; rho_13: 0.5792; rho_23: 0.6570; discrepancy: 6294.685\n",
      "variance_1: 99.52; variance_2: 92.27; variance_3: 21.00; rho_12: 0.6169; rho_13: 0.6182; rho_23: 0.6774; discrepancy: 6300.945\n",
      "variance_1: 100.72; variance_2: 95.81; variance_3: 14.42; rho_12: 0.6346; rho_13: 0.5802; rho_23: 0.6926; discrepancy: 6317.125\n",
      "variance_1: 97.75; variance_2: 98.95; variance_3: 54.16; rho_12: 0.5628; rho_13: 0.5784; rho_23: 0.6065; discrepancy: 6300.995\n",
      "variance_1: 95.29; variance_2: 98.92; variance_3: 17.25; rho_12: 0.6006; rho_13: 0.5977; rho_23: 0.7194; discrepancy: 6305.796\n",
      "variance_1: 96.74; variance_2: 98.54; variance_3: 28.43; rho_12: 0.5930; rho_13: 0.5895; rho_23: 0.6808; discrepancy: 6294.607\n",
      "variance_1: 98.28; variance_2: 97.23; variance_3: 16.49; rho_12: 0.6182; rho_13: 0.5878; rho_23: 0.7025; discrepancy: 6309.479\n",
      "variance_1: 97.88; variance_2: 98.52; variance_3: 44.74; rho_12: 0.5767; rho_13: 0.5808; rho_23: 0.6305; discrepancy: 6297.058\n",
      "variance_1: 95.96; variance_2: 106.00; variance_3: 57.56; rho_12: 0.5507; rho_13: 0.5356; rho_23: 0.6159; discrepancy: 6302.908\n",
      "variance_1: 98.63; variance_2: 95.70; variance_3: 30.14; rho_12: 0.6004; rho_13: 0.5975; rho_23: 0.6620; discrepancy: 6294.902\n",
      "variance_1: 93.74; variance_2: 90.17; variance_3: 22.68; rho_12: 0.6233; rho_13: 0.6020; rho_23: 0.7113; discrepancy: 6297.506\n",
      "variance_1: 91.32; variance_2: 97.08; variance_3: 13.76; rho_12: 0.6450; rho_13: 0.6150; rho_23: 0.6884; discrepancy: 6316.676\n",
      "variance_1: 98.56; variance_2: 96.35; variance_3: 40.52; rho_12: 0.5800; rho_13: 0.5761; rho_23: 0.6570; discrepancy: 6295.675\n",
      "variance_1: 100.17; variance_2: 105.08; variance_3: 46.47; rho_12: 0.5656; rho_13: 0.5675; rho_23: 0.6056; discrepancy: 6298.760\n",
      "variance_1: 95.34; variance_2: 93.90; variance_3: 28.63; rho_12: 0.6089; rho_13: 0.5934; rho_23: 0.6848; discrepancy: 6294.437\n",
      "variance_1: 95.17; variance_2: 95.19; variance_3: 19.04; rho_12: 0.6229; rho_13: 0.5930; rho_23: 0.7045; discrepancy: 6303.220\n",
      "variance_1: 97.21; variance_2: 97.69; variance_3: 38.32; rho_12: 0.5882; rho_13: 0.5838; rho_23: 0.6490; discrepancy: 6295.004\n",
      "variance_1: 94.05; variance_2: 97.80; variance_3: 22.52; rho_12: 0.6224; rho_13: 0.6002; rho_23: 0.6753; discrepancy: 6298.505\n",
      "variance_1: 97.43; variance_2: 96.72; variance_3: 36.02; rho_12: 0.5906; rho_13: 0.5821; rho_23: 0.6616; discrepancy: 6294.584\n",
      "variance_1: 95.48; variance_2: 96.14; variance_3: 23.97; rho_12: 0.6149; rho_13: 0.5919; rho_23: 0.6875; discrepancy: 6297.231\n",
      "variance_1: 96.77; variance_2: 97.30; variance_3: 34.73; rho_12: 0.5949; rho_13: 0.5858; rho_23: 0.6586; discrepancy: 6294.389\n",
      "variance_1: 93.43; variance_2: 98.66; variance_3: 33.67; rho_12: 0.6009; rho_13: 0.5743; rho_23: 0.6733; discrepancy: 6293.819\n",
      "variance_1: 90.83; variance_2: 100.14; variance_3: 35.43; rho_12: 0.6012; rho_13: 0.5627; rho_23: 0.6789; discrepancy: 6293.596\n",
      "variance_1: 93.46; variance_2: 95.75; variance_3: 29.81; rho_12: 0.5862; rho_13: 0.5871; rho_23: 0.6856; discrepancy: 6293.664\n",
      "variance_1: 92.29; variance_2: 95.27; variance_3: 36.20; rho_12: 0.6025; rho_13: 0.5760; rho_23: 0.6635; discrepancy: 6294.092\n",
      "variance_1: 95.47; variance_2: 95.39; variance_3: 37.68; rho_12: 0.5899; rho_13: 0.5770; rho_23: 0.6811; discrepancy: 6294.096\n",
      "variance_1: 90.62; variance_2: 95.87; variance_3: 31.47; rho_12: 0.6039; rho_13: 0.5785; rho_23: 0.6893; discrepancy: 6293.150\n",
      "variance_1: 87.22; variance_2: 95.44; variance_3: 29.19; rho_12: 0.6106; rho_13: 0.5767; rho_23: 0.7032; discrepancy: 6292.899\n",
      "variance_1: 90.00; variance_2: 99.20; variance_3: 39.05; rho_12: 0.5862; rho_13: 0.5617; rho_23: 0.6721; discrepancy: 6294.014\n",
      "variance_1: 86.31; variance_2: 96.43; variance_3: 34.39; rho_12: 0.5973; rho_13: 0.5613; rho_23: 0.7029; discrepancy: 6292.465\n",
      "variance_1: 81.08; variance_2: 95.99; variance_3: 34.22; rho_12: 0.5985; rho_13: 0.5490; rho_23: 0.7250; discrepancy: 6291.678\n",
      "variance_1: 82.82; variance_2: 98.54; variance_3: 30.29; rho_12: 0.6052; rho_13: 0.5608; rho_23: 0.6949; discrepancy: 6292.559\n",
      "variance_1: 82.85; variance_2: 99.74; variance_3: 29.80; rho_12: 0.5935; rho_13: 0.5567; rho_23: 0.7231; discrepancy: 6292.000\n",
      "variance_1: 82.75; variance_2: 96.00; variance_3: 23.86; rho_12: 0.6122; rho_13: 0.5692; rho_23: 0.7314; discrepancy: 6294.797\n",
      "variance_1: 88.19; variance_2: 98.40; variance_3: 35.25; rho_12: 0.5927; rho_13: 0.5636; rho_23: 0.6870; discrepancy: 6292.954\n",
      "variance_1: 77.53; variance_2: 100.34; variance_3: 34.92; rho_12: 0.6144; rho_13: 0.5361; rho_23: 0.7184; discrepancy: 6291.762\n",
      "variance_1: 75.74; variance_2: 96.01; variance_3: 29.13; rho_12: 0.6037; rho_13: 0.5516; rho_23: 0.7383; discrepancy: 6291.213\n",
      "variance_1: 68.19; variance_2: 93.95; variance_3: 25.97; rho_12: 0.6050; rho_13: 0.5460; rho_23: 0.7680; discrepancy: 6291.262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance_1: 74.23; variance_2: 96.96; variance_3: 27.26; rho_12: 0.6159; rho_13: 0.5467; rho_23: 0.7473; discrepancy: 6291.820\n",
      "variance_1: 70.87; variance_2: 100.42; variance_3: 32.68; rho_12: 0.5998; rho_13: 0.5235; rho_23: 0.7459; discrepancy: 6290.827\n",
      "variance_1: 62.69; variance_2: 102.91; variance_3: 34.43; rho_12: 0.5944; rho_13: 0.4969; rho_23: 0.7672; discrepancy: 6290.707\n",
      "variance_1: 68.55; variance_2: 98.77; variance_3: 32.97; rho_12: 0.6016; rho_13: 0.5182; rho_23: 0.7782; discrepancy: 6290.315\n",
      "variance_1: 61.41; variance_2: 98.89; variance_3: 34.31; rho_12: 0.5998; rho_13: 0.4968; rho_23: 0.8198; discrepancy: 6290.172\n",
      "variance_1: 61.38; variance_2: 97.28; variance_3: 34.96; rho_12: 0.6154; rho_13: 0.5023; rho_23: 0.7822; discrepancy: 6290.414\n",
      "variance_1: 65.72; variance_2: 100.18; variance_3: 40.06; rho_12: 0.5928; rho_13: 0.4976; rho_23: 0.7696; discrepancy: 6291.730\n",
      "variance_1: 58.47; variance_2: 96.75; variance_3: 34.11; rho_12: 0.5872; rho_13: 0.4953; rho_23: 0.8156; discrepancy: 6289.994\n",
      "variance_1: 48.95; variance_2: 94.96; variance_3: 33.70; rho_12: 0.5736; rho_13: 0.4749; rho_23: 0.8643; discrepancy: 6290.493\n",
      "variance_1: 67.87; variance_2: 95.76; variance_3: 26.99; rho_12: 0.6068; rho_13: 0.5331; rho_23: 0.7798; discrepancy: 6291.077\n",
      "variance_1: 48.11; variance_2: 99.88; variance_3: 30.42; rho_12: 0.6040; rho_13: 0.4764; rho_23: 0.8426; discrepancy: 6290.877\n",
      "variance_1: 44.24; variance_2: 101.14; variance_3: 35.95; rho_12: 0.5988; rho_13: 0.4487; rho_23: 0.8641; discrepancy: 6292.618\n",
      "variance_1: 67.86; variance_2: 97.29; variance_3: 30.83; rho_12: 0.6025; rho_13: 0.5259; rho_23: 0.7697; discrepancy: 6290.261\n",
      "variance_1: 52.10; variance_2: 101.91; variance_3: 39.36; rho_12: 0.5942; rho_13: 0.4648; rho_23: 0.8193; discrepancy: 6291.923\n",
      "variance_1: 63.93; variance_2: 97.30; variance_3: 30.08; rho_12: 0.6037; rho_13: 0.5160; rho_23: 0.7897; discrepancy: 6290.166\n",
      "variance_1: 77.14; variance_2: 96.93; variance_3: 35.82; rho_12: 0.5970; rho_13: 0.5347; rho_23: 0.7388; discrepancy: 6291.442\n",
      "variance_1: 55.37; variance_2: 99.14; variance_3: 31.77; rho_12: 0.6022; rho_13: 0.4909; rho_23: 0.8167; discrepancy: 6290.151\n",
      "variance_1: 60.12; variance_2: 92.64; variance_3: 30.92; rho_12: 0.6092; rho_13: 0.5122; rho_23: 0.8307; discrepancy: 6289.548\n",
      "variance_1: 58.83; variance_2: 87.51; variance_3: 29.17; rho_12: 0.6167; rho_13: 0.5199; rho_23: 0.8624; discrepancy: 6289.370\n",
      "variance_1: 60.58; variance_2: 95.01; variance_3: 28.47; rho_12: 0.5886; rho_13: 0.5126; rho_23: 0.8424; discrepancy: 6289.834\n",
      "variance_1: 51.67; variance_2: 94.24; variance_3: 31.81; rho_12: 0.5969; rho_13: 0.4847; rho_23: 0.8791; discrepancy: 6290.185\n",
      "variance_1: 55.72; variance_2: 95.00; variance_3: 31.56; rho_12: 0.5983; rho_13: 0.4950; rho_23: 0.8518; discrepancy: 6289.820\n",
      "variance_1: 56.22; variance_2: 91.35; variance_3: 27.41; rho_12: 0.5991; rho_13: 0.5131; rho_23: 0.8397; discrepancy: 6290.024\n",
      "variance_1: 51.13; variance_2: 90.96; variance_3: 30.75; rho_12: 0.5937; rho_13: 0.4929; rho_23: 0.8866; discrepancy: 6289.795\n",
      "variance_1: 58.28; variance_2: 86.39; variance_3: 28.72; rho_12: 0.5923; rho_13: 0.5187; rho_23: 0.8828; discrepancy: 6289.250\n",
      "variance_1: 59.74; variance_2: 80.01; variance_3: 27.20; rho_12: 0.5873; rho_13: 0.5325; rho_23: 0.9159; discrepancy: 6289.223\n",
      "variance_1: 58.61; variance_2: 90.40; variance_3: 33.01; rho_12: 0.5915; rho_13: 0.5030; rho_23: 0.8852; discrepancy: 6289.441\n",
      "variance_1: 56.39; variance_2: 82.88; variance_3: 25.94; rho_12: 0.6048; rho_13: 0.5233; rho_23: 0.9325; discrepancy: 6290.130\n",
      "variance_1: 57.95; variance_2: 93.28; variance_3: 32.07; rho_12: 0.5916; rho_13: 0.5023; rho_23: 0.8448; discrepancy: 6289.530\n",
      "variance_1: 53.41; variance_2: 84.05; variance_3: 32.78; rho_12: 0.6044; rho_13: 0.5026; rho_23: 0.9065; discrepancy: 6289.401\n",
      "variance_1: 57.51; variance_2: 80.40; variance_3: 30.09; rho_12: 0.5967; rho_13: 0.5228; rho_23: 0.9154; discrepancy: 6288.794\n",
      "variance_1: 58.41; variance_2: 73.10; variance_3: 29.36; rho_12: 0.5959; rho_13: 0.5367; rho_23: 0.9472; discrepancy: 6288.534\n",
      "variance_1: 64.52; variance_2: 78.49; variance_3: 30.45; rho_12: 0.6021; rho_13: 0.5394; rho_23: 0.9008; discrepancy: 6288.685\n",
      "variance_1: 59.88; variance_2: 71.24; variance_3: 28.59; rho_12: 0.6077; rho_13: 0.5424; rho_23: 0.9612; discrepancy: 6288.749\n",
      "variance_1: 59.66; variance_2: 67.74; variance_3: 26.18; rho_12: 0.6132; rho_13: 0.5548; rho_23: 0.9461; discrepancy: 6289.186\n",
      "variance_1: 66.93; variance_2: 68.65; variance_3: 24.20; rho_12: 0.6032; rho_13: 0.5726; rho_23: 0.9380; discrepancy: 6290.237\n",
      "variance_1: 56.79; variance_2: 80.20; variance_3: 30.64; rho_12: 0.6041; rho_13: 0.5201; rho_23: 0.9144; discrepancy: 6288.875\n",
      "variance_1: 60.84; variance_2: 62.75; variance_3: 28.30; rho_12: 0.5868; rho_13: 0.5554; rho_23: 0.9994; discrepancy: 6288.690\n",
      "variance_1: 60.29; variance_2: 64.49; variance_3: 30.64; rho_12: 0.6160; rho_13: 0.5504; rho_23: 0.9738; discrepancy: 6288.436\n",
      "variance_1: 60.56; variance_2: 56.73; variance_3: 32.36; rho_12: 0.6304; rho_13: 0.5594; rho_23: 1.0027; discrepancy: 6288.699\n",
      "variance_1: 60.58; variance_2: 75.69; variance_3: 33.15; rho_12: 0.5910; rho_13: 0.5267; rho_23: 0.9528; discrepancy: 6288.846\n",
      "variance_1: 64.71; variance_2: 61.72; variance_3: 29.53; rho_12: 0.5957; rho_13: 0.5635; rho_23: 0.9973; discrepancy: 6288.549\n",
      "variance_1: 62.30; variance_2: 61.58; variance_3: 25.81; rho_12: 0.6104; rho_13: 0.5693; rho_23: 0.9738; discrepancy: 6289.277\n",
      "variance_1: 61.01; variance_2: 72.16; variance_3: 31.31; rho_12: 0.5959; rho_13: 0.5373; rho_23: 0.9580; discrepancy: 6288.548\n",
      "variance_1: 63.38; variance_2: 66.33; variance_3: 31.27; rho_12: 0.5898; rho_13: 0.5519; rho_23: 0.9643; discrepancy: 6288.354\n",
      "variance_1: 65.12; variance_2: 63.88; variance_3: 32.62; rho_12: 0.5808; rho_13: 0.5566; rho_23: 0.9659; discrepancy: 6288.451\n",
      "variance_1: 63.27; variance_2: 76.02; variance_3: 32.55; rho_12: 0.6117; rho_13: 0.5377; rho_23: 0.9144; discrepancy: 6288.592\n",
      "variance_1: 59.17; variance_2: 59.45; variance_3: 31.11; rho_12: 0.5996; rho_13: 0.5531; rho_23: 1.0175; discrepancy: 6288.594\n",
      "variance_1: 60.51; variance_2: 64.21; variance_3: 30.94; rho_12: 0.6002; rho_13: 0.5497; rho_23: 0.9883; discrepancy: 6288.434\n",
      "variance_1: 59.50; variance_2: 57.99; variance_3: 28.46; rho_12: 0.5861; rho_13: 0.5588; rho_23: 1.0286; discrepancy: 6288.827\n",
      "variance_1: 62.33; variance_2: 71.51; variance_3: 31.53; rho_12: 0.6053; rho_13: 0.5430; rho_23: 0.9429; discrepancy: 6288.428\n",
      "variance_1: 57.26; variance_2: 75.55; variance_3: 32.16; rho_12: 0.6053; rho_13: 0.5261; rho_23: 0.9276; discrepancy: 6288.625\n",
      "variance_1: 62.85; variance_2: 65.18; variance_3: 30.18; rho_12: 0.5981; rho_13: 0.5542; rho_23: 0.9799; discrepancy: 6288.427\n",
      "variance_1: 61.57; variance_2: 62.78; variance_3: 30.00; rho_12: 0.6059; rho_13: 0.5580; rho_23: 0.9741; discrepancy: 6288.317\n",
      "variance_1: 61.85; variance_2: 58.10; variance_3: 29.34; rho_12: 0.6110; rho_13: 0.5683; rho_23: 0.9822; discrepancy: 6288.373\n",
      "variance_1: 65.23; variance_2: 58.40; variance_3: 32.16; rho_12: 0.6092; rho_13: 0.5657; rho_23: 0.9939; discrepancy: 6288.632\n",
      "variance_1: 60.11; variance_2: 69.43; variance_3: 30.06; rho_12: 0.5992; rho_13: 0.5439; rho_23: 0.9589; discrepancy: 6288.399\n",
      "variance_1: 63.29; variance_2: 68.66; variance_3: 30.69; rho_12: 0.5835; rho_13: 0.5498; rho_23: 0.9624; discrepancy: 6288.313\n",
      "variance_1: 64.79; variance_2: 70.74; variance_3: 30.72; rho_12: 0.5673; rho_13: 0.5494; rho_23: 0.9567; discrepancy: 6288.302\n",
      "variance_1: 64.50; variance_2: 71.11; variance_3: 30.31; rho_12: 0.5884; rho_13: 0.5504; rho_23: 0.9373; discrepancy: 6288.339\n",
      "variance_1: 63.41; variance_2: 63.68; variance_3: 29.32; rho_12: 0.5776; rho_13: 0.5597; rho_23: 0.9808; discrepancy: 6288.370\n",
      "variance_1: 63.07; variance_2: 69.51; variance_3: 30.38; rho_12: 0.5779; rho_13: 0.5503; rho_23: 0.9442; discrepancy: 6288.222\n",
      "variance_1: 63.18; variance_2: 71.68; variance_3: 30.47; rho_12: 0.5678; rho_13: 0.5483; rho_23: 0.9263; discrepancy: 6288.183\n",
      "variance_1: 66.83; variance_2: 66.01; variance_3: 30.64; rho_12: 0.5663; rho_13: 0.5620; rho_23: 0.9543; discrepancy: 6288.273\n",
      "variance_1: 64.68; variance_2: 72.54; variance_3: 31.82; rho_12: 0.5842; rho_13: 0.5470; rho_23: 0.9236; discrepancy: 6288.311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance_1: 65.14; variance_2: 71.96; variance_3: 30.05; rho_12: 0.5702; rho_13: 0.5532; rho_23: 0.9264; discrepancy: 6288.209\n",
      "variance_1: 64.23; variance_2: 67.46; variance_3: 30.92; rho_12: 0.5656; rho_13: 0.5555; rho_23: 0.9499; discrepancy: 6288.133\n",
      "variance_1: 64.09; variance_2: 65.63; variance_3: 31.22; rho_12: 0.5542; rho_13: 0.5580; rho_23: 0.9562; discrepancy: 6288.096\n",
      "variance_1: 68.00; variance_2: 76.73; variance_3: 31.64; rho_12: 0.5308; rho_13: 0.5480; rho_23: 0.9070; discrepancy: 6288.371\n",
      "variance_1: 63.18; variance_2: 66.27; variance_3: 30.41; rho_12: 0.5871; rho_13: 0.5555; rho_23: 0.9574; discrepancy: 6288.213\n",
      "variance_1: 64.40; variance_2: 64.89; variance_3: 29.35; rho_12: 0.5534; rho_13: 0.5618; rho_23: 0.9689; discrepancy: 6288.217\n",
      "variance_1: 64.15; variance_2: 64.74; variance_3: 29.99; rho_12: 0.5658; rho_13: 0.5634; rho_23: 0.9398; discrepancy: 6288.099\n",
      "variance_1: 61.22; variance_2: 69.04; variance_3: 29.86; rho_12: 0.5665; rho_13: 0.5514; rho_23: 0.9374; discrepancy: 6288.034\n",
      "variance_1: 58.41; variance_2: 70.56; variance_3: 29.47; rho_12: 0.5666; rho_13: 0.5462; rho_23: 0.9289; discrepancy: 6288.007\n",
      "variance_1: 61.65; variance_2: 72.06; variance_3: 31.19; rho_12: 0.5838; rho_13: 0.5464; rho_23: 0.9094; discrepancy: 6288.119\n",
      "variance_1: 62.37; variance_2: 72.60; variance_3: 30.39; rho_12: 0.5490; rho_13: 0.5497; rho_23: 0.9050; discrepancy: 6288.024\n",
      "variance_1: 59.48; variance_2: 67.13; variance_3: 30.86; rho_12: 0.5589; rho_13: 0.5509; rho_23: 0.9288; discrepancy: 6287.928\n",
      "variance_1: 56.64; variance_2: 64.72; variance_3: 31.27; rho_12: 0.5532; rho_13: 0.5497; rho_23: 0.9300; discrepancy: 6287.910\n",
      "variance_1: 59.26; variance_2: 65.09; variance_3: 30.70; rho_12: 0.5564; rho_13: 0.5562; rho_23: 0.9301; discrepancy: 6287.823\n",
      "variance_1: 57.29; variance_2: 61.80; variance_3: 30.82; rho_12: 0.5506; rho_13: 0.5601; rho_23: 0.9320; discrepancy: 6287.761\n",
      "variance_1: 59.33; variance_2: 61.29; variance_3: 29.86; rho_12: 0.5293; rho_13: 0.5626; rho_23: 0.9545; discrepancy: 6287.936\n",
      "variance_1: 55.23; variance_2: 67.46; variance_3: 31.02; rho_12: 0.5352; rho_13: 0.5454; rho_23: 0.9290; discrepancy: 6287.798\n",
      "variance_1: 52.33; variance_2: 67.18; variance_3: 29.73; rho_12: 0.5405; rho_13: 0.5466; rho_23: 0.9036; discrepancy: 6287.865\n",
      "variance_1: 50.71; variance_2: 58.40; variance_3: 30.34; rho_12: 0.5428; rho_13: 0.5538; rho_23: 0.9543; discrepancy: 6287.985\n",
      "variance_1: 52.10; variance_2: 56.40; variance_3: 31.54; rho_12: 0.5173; rho_13: 0.5599; rho_23: 0.9389; discrepancy: 6288.163\n",
      "variance_1: 56.83; variance_2: 67.02; variance_3: 29.99; rho_12: 0.5543; rho_13: 0.5496; rho_23: 0.9314; discrepancy: 6287.838\n",
      "variance_1: 61.84; variance_2: 71.42; variance_3: 30.56; rho_12: 0.5449; rho_13: 0.5508; rho_23: 0.9058; discrepancy: 6287.969\n",
      "variance_1: 59.06; variance_2: 68.17; variance_3: 30.50; rho_12: 0.5444; rho_13: 0.5516; rho_23: 0.9180; discrepancy: 6287.844\n",
      "variance_1: 53.13; variance_2: 70.82; variance_3: 31.25; rho_12: 0.5634; rho_13: 0.5383; rho_23: 0.8935; discrepancy: 6287.913\n",
      "variance_1: 54.68; variance_2: 68.44; variance_3: 30.90; rho_12: 0.5549; rho_13: 0.5444; rho_23: 0.9087; discrepancy: 6287.820\n",
      "variance_1: 55.16; variance_2: 68.63; variance_3: 29.71; rho_12: 0.5401; rho_13: 0.5495; rho_23: 0.9109; discrepancy: 6287.709\n",
      "variance_1: 54.43; variance_2: 70.59; variance_3: 28.93; rho_12: 0.5335; rho_13: 0.5494; rho_23: 0.9014; discrepancy: 6287.709\n",
      "variance_1: 60.18; variance_2: 67.31; variance_3: 30.99; rho_12: 0.5505; rho_13: 0.5536; rho_23: 0.9366; discrepancy: 6287.786\n",
      "variance_1: 53.82; variance_2: 66.04; variance_3: 30.38; rho_12: 0.5486; rho_13: 0.5493; rho_23: 0.9284; discrepancy: 6287.658\n",
      "variance_1: 51.20; variance_2: 64.97; variance_3: 30.32; rho_12: 0.5508; rho_13: 0.5481; rho_23: 0.9337; discrepancy: 6287.646\n",
      "variance_1: 54.17; variance_2: 66.50; variance_3: 31.00; rho_12: 0.5376; rho_13: 0.5507; rho_23: 0.9158; discrepancy: 6287.579\n",
      "variance_1: 52.84; variance_2: 66.25; variance_3: 31.51; rho_12: 0.5292; rho_13: 0.5513; rho_23: 0.9080; discrepancy: 6287.525\n",
      "variance_1: 55.71; variance_2: 64.35; variance_3: 30.30; rho_12: 0.5284; rho_13: 0.5582; rho_23: 0.9382; discrepancy: 6287.485\n",
      "variance_1: 56.22; variance_2: 62.31; variance_3: 30.00; rho_12: 0.5152; rho_13: 0.5651; rho_23: 0.9529; discrepancy: 6287.408\n",
      "variance_1: 55.49; variance_2: 63.61; variance_3: 29.84; rho_12: 0.5414; rho_13: 0.5639; rho_23: 0.9258; discrepancy: 6287.347\n",
      "variance_1: 55.62; variance_2: 61.69; variance_3: 29.25; rho_12: 0.5445; rho_13: 0.5732; rho_23: 0.9242; discrepancy: 6287.205\n",
      "variance_1: 49.02; variance_2: 61.89; variance_3: 29.28; rho_12: 0.5241; rho_13: 0.5621; rho_23: 0.9141; discrepancy: 6287.482\n",
      "variance_1: 49.15; variance_2: 67.43; variance_3: 28.94; rho_12: 0.5151; rho_13: 0.5563; rho_23: 0.9128; discrepancy: 6287.274\n",
      "variance_1: 50.26; variance_2: 57.60; variance_3: 30.84; rho_12: 0.5261; rho_13: 0.5693; rho_23: 0.9471; discrepancy: 6287.297\n",
      "variance_1: 53.17; variance_2: 60.75; variance_3: 29.62; rho_12: 0.5007; rho_13: 0.5777; rho_23: 0.9193; discrepancy: 6287.071\n",
      "variance_1: 54.15; variance_2: 58.65; variance_3: 29.28; rho_12: 0.4756; rho_13: 0.5925; rho_23: 0.9122; discrepancy: 6287.075\n",
      "variance_1: 51.64; variance_2: 57.64; variance_3: 27.80; rho_12: 0.5127; rho_13: 0.5833; rho_23: 0.9489; discrepancy: 6287.188\n",
      "variance_1: 56.33; variance_2: 60.58; variance_3: 29.53; rho_12: 0.5140; rho_13: 0.5795; rho_23: 0.9543; discrepancy: 6286.942\n",
      "variance_1: 59.98; variance_2: 59.93; variance_3: 29.66; rho_12: 0.5089; rho_13: 0.5881; rho_23: 0.9743; discrepancy: 6286.897\n",
      "variance_1: 50.39; variance_2: 59.37; variance_3: 28.71; rho_12: 0.5208; rho_13: 0.5841; rho_23: 0.9226; discrepancy: 6286.769\n",
      "variance_1: 47.48; variance_2: 57.91; variance_3: 28.06; rho_12: 0.5237; rho_13: 0.5936; rho_23: 0.9075; discrepancy: 6286.694\n",
      "variance_1: 55.42; variance_2: 64.19; variance_3: 26.94; rho_12: 0.5091; rho_13: 0.5881; rho_23: 0.9152; discrepancy: 6286.942\n",
      "variance_1: 58.62; variance_2: 53.27; variance_3: 28.17; rho_12: 0.5181; rho_13: 0.6117; rho_23: 0.9504; discrepancy: 6287.030\n",
      "variance_1: 53.15; variance_2: 56.20; variance_3: 27.50; rho_12: 0.4799; rho_13: 0.6076; rho_23: 0.9477; discrepancy: 6286.648\n",
      "variance_1: 51.91; variance_2: 53.46; variance_3: 26.63; rho_12: 0.4475; rho_13: 0.6249; rho_23: 0.9594; discrepancy: 6286.779\n",
      "variance_1: 57.63; variance_2: 59.77; variance_3: 28.85; rho_12: 0.5007; rho_13: 0.6057; rho_23: 0.9226; discrepancy: 6286.342\n",
      "variance_1: 60.62; variance_2: 60.84; variance_3: 29.38; rho_12: 0.4948; rho_13: 0.6169; rho_23: 0.9095; discrepancy: 6286.110\n",
      "variance_1: 58.59; variance_2: 56.69; variance_3: 26.95; rho_12: 0.5108; rho_13: 0.6243; rho_23: 0.9489; discrepancy: 6286.255\n",
      "variance_1: 53.13; variance_2: 65.32; variance_3: 28.00; rho_12: 0.4910; rho_13: 0.5945; rho_23: 0.9174; discrepancy: 6286.015\n",
      "variance_1: 50.38; variance_2: 71.34; variance_3: 27.91; rho_12: 0.4774; rho_13: 0.5860; rho_23: 0.9008; discrepancy: 6285.874\n",
      "variance_1: 54.65; variance_2: 56.78; variance_3: 29.55; rho_12: 0.4894; rho_13: 0.6175; rho_23: 0.9477; discrepancy: 6285.736\n",
      "variance_1: 54.26; variance_2: 53.07; variance_3: 30.85; rho_12: 0.4796; rho_13: 0.6322; rho_23: 0.9640; discrepancy: 6285.651\n",
      "variance_1: 48.18; variance_2: 58.76; variance_3: 27.23; rho_12: 0.4798; rho_13: 0.6321; rho_23: 0.8851; discrepancy: 6285.626\n",
      "variance_1: 42.27; variance_2: 58.18; variance_3: 26.01; rho_12: 0.4652; rho_13: 0.6540; rho_23: 0.8405; discrepancy: 6286.159\n",
      "variance_1: 60.92; variance_2: 61.06; variance_3: 28.55; rho_12: 0.4504; rho_13: 0.6394; rho_23: 0.9445; discrepancy: 6285.368\n",
      "variance_1: 67.64; variance_2: 62.64; variance_3: 28.79; rho_12: 0.4137; rho_13: 0.6623; rho_23: 0.9630; discrepancy: 6285.526\n",
      "variance_1: 57.83; variance_2: 64.39; variance_3: 29.46; rho_12: 0.4844; rho_13: 0.6360; rho_23: 0.9033; discrepancy: 6284.574\n",
      "variance_1: 60.17; variance_2: 68.48; variance_3: 30.44; rho_12: 0.4866; rho_13: 0.6501; rho_23: 0.8811; discrepancy: 6283.877\n",
      "variance_1: 52.92; variance_2: 67.82; variance_3: 31.17; rho_12: 0.4454; rho_13: 0.6279; rho_23: 0.8795; discrepancy: 6284.571\n",
      "variance_1: 48.32; variance_2: 66.01; variance_3: 29.33; rho_12: 0.4450; rho_13: 0.6390; rho_23: 0.9088; discrepancy: 6283.869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance_1: 42.16; variance_2: 68.59; variance_3: 29.30; rho_12: 0.4201; rho_13: 0.6500; rho_23: 0.9084; discrepancy: 6283.493\n",
      "variance_1: 55.82; variance_2: 54.59; variance_3: 31.26; rho_12: 0.4431; rho_13: 0.6913; rho_23: 0.9200; discrepancy: 6284.255\n",
      "variance_1: 52.46; variance_2: 73.36; variance_3: 28.46; rho_12: 0.4289; rho_13: 0.6648; rho_23: 0.8422; discrepancy: 6283.376\n",
      "variance_1: 51.57; variance_2: 83.50; variance_3: 27.27; rho_12: 0.4036; rho_13: 0.6811; rho_23: 0.7814; discrepancy: 6283.458\n",
      "variance_1: 59.98; variance_2: 72.54; variance_3: 32.50; rho_12: 0.4117; rho_13: 0.6757; rho_23: 0.9067; discrepancy: 6283.124\n",
      "variance_1: 65.88; variance_2: 79.43; variance_3: 35.14; rho_12: 0.3777; rho_13: 0.6976; rho_23: 0.9175; discrepancy: 6283.579\n",
      "variance_1: 46.92; variance_2: 74.06; variance_3: 32.50; rho_12: 0.4283; rho_13: 0.6805; rho_23: 0.8348; discrepancy: 6282.349\n",
      "variance_1: 39.92; variance_2: 80.56; variance_3: 34.48; rho_12: 0.4172; rho_13: 0.7011; rho_23: 0.7799; discrepancy: 6282.565\n",
      "variance_1: 52.92; variance_2: 69.38; variance_3: 30.32; rho_12: 0.4275; rho_13: 0.7096; rho_23: 0.8849; discrepancy: 6281.548\n",
      "variance_1: 52.92; variance_2: 70.16; variance_3: 29.89; rho_12: 0.4186; rho_13: 0.7505; rho_23: 0.8877; discrepancy: 6280.460\n",
      "variance_1: 49.05; variance_2: 87.80; variance_3: 29.77; rho_12: 0.4216; rho_13: 0.6660; rho_23: 0.8336; discrepancy: 6281.730\n",
      "variance_1: 40.99; variance_2: 80.36; variance_3: 30.38; rho_12: 0.3564; rho_13: 0.7124; rho_23: 0.8568; discrepancy: 6281.781\n",
      "variance_1: 58.61; variance_2: 84.17; variance_3: 31.86; rho_12: 0.4018; rho_13: 0.7333; rho_23: 0.8122; discrepancy: 6281.315\n",
      "variance_1: 50.36; variance_2: 83.01; variance_3: 33.84; rho_12: 0.3839; rho_13: 0.7413; rho_23: 0.8684; discrepancy: 6280.383\n",
      "variance_1: 49.31; variance_2: 87.83; variance_3: 36.52; rho_12: 0.3614; rho_13: 0.7796; rho_23: 0.8814; discrepancy: 6280.600\n",
      "variance_1: 39.65; variance_2: 87.32; variance_3: 30.24; rho_12: 0.3917; rho_13: 0.7522; rho_23: 0.7911; discrepancy: 6280.274\n",
      "variance_1: 29.48; variance_2: 94.70; variance_3: 29.12; rho_12: 0.3817; rho_13: 0.7904; rho_23: 0.7332; discrepancy: 6282.660\n",
      "variance_1: 50.28; variance_2: 90.21; variance_3: 29.49; rho_12: 0.3631; rho_13: 0.7713; rho_23: 0.8484; discrepancy: 6279.299\n",
      "variance_1: 51.95; variance_2: 98.29; variance_3: 27.99; rho_12: 0.3305; rho_13: 0.8168; rho_23: 0.8553; discrepancy: 6278.974\n",
      "variance_1: 59.86; variance_2: 89.89; variance_3: 30.82; rho_12: 0.4263; rho_13: 0.7743; rho_23: 0.8260; discrepancy: 6279.375\n",
      "variance_1: 55.40; variance_2: 83.14; variance_3: 31.78; rho_12: 0.3626; rho_13: 0.8568; rho_23: 0.8466; discrepancy: 6279.890\n",
      "variance_1: 44.77; variance_2: 86.42; variance_3: 29.66; rho_12: 0.3694; rho_13: 0.8307; rho_23: 0.8794; discrepancy: 6278.195\n",
      "variance_1: 37.84; variance_2: 87.55; variance_3: 28.56; rho_12: 0.3533; rho_13: 0.8794; rho_23: 0.9131; discrepancy: 6278.849\n",
      "variance_1: 47.74; variance_2: 105.86; variance_3: 31.55; rho_12: 0.3362; rho_13: 0.8402; rho_23: 0.8012; discrepancy: 6278.609\n",
      "variance_1: 49.42; variance_2: 100.63; variance_3: 26.85; rho_12: 0.3550; rho_13: 0.8824; rho_23: 0.7982; discrepancy: 6278.412\n",
      "variance_1: 63.40; variance_2: 100.76; variance_3: 29.31; rho_12: 0.3350; rho_13: 0.9149; rho_23: 0.8778; discrepancy: 6280.717\n",
      "variance_1: 45.58; variance_2: 90.68; variance_3: 30.01; rho_12: 0.3775; rho_13: 0.7929; rho_23: 0.8128; discrepancy: 6278.802\n",
      "variance_1: 44.37; variance_2: 107.45; variance_3: 27.18; rho_12: 0.3690; rho_13: 0.7889; rho_23: 0.8111; discrepancy: 6278.158\n",
      "variance_1: 38.86; variance_2: 119.61; variance_3: 24.88; rho_12: 0.3722; rho_13: 0.7550; rho_23: 0.7933; discrepancy: 6279.703\n",
      "variance_1: 34.76; variance_2: 106.56; variance_3: 26.92; rho_12: 0.2863; rho_13: 0.8763; rho_23: 0.8267; discrepancy: 6280.470\n",
      "variance_1: 53.58; variance_2: 94.05; variance_3: 29.85; rho_12: 0.3913; rho_13: 0.7998; rho_23: 0.8262; discrepancy: 6278.441\n",
      "variance_1: 43.20; variance_2: 96.75; variance_3: 30.38; rho_12: 0.4024; rho_13: 0.8282; rho_23: 0.7877; discrepancy: 6277.682\n",
      "variance_1: 38.83; variance_2: 95.98; variance_3: 31.57; rho_12: 0.4383; rho_13: 0.8339; rho_23: 0.7539; discrepancy: 6277.973\n",
      "variance_1: 48.78; variance_2: 106.38; variance_3: 28.48; rho_12: 0.3636; rho_13: 0.8639; rho_23: 0.8218; discrepancy: 6277.327\n",
      "variance_1: 50.37; variance_2: 114.23; variance_3: 27.71; rho_12: 0.3566; rho_13: 0.8994; rho_23: 0.8263; discrepancy: 6277.294\n",
      "variance_1: 47.50; variance_2: 93.98; variance_3: 25.66; rho_12: 0.4117; rho_13: 0.8362; rho_23: 0.8417; discrepancy: 6277.457\n",
      "variance_1: 39.63; variance_2: 105.77; variance_3: 25.96; rho_12: 0.3634; rho_13: 0.8888; rho_23: 0.8220; discrepancy: 6277.432\n",
      "variance_1: 40.53; variance_2: 100.91; variance_3: 28.67; rho_12: 0.4025; rho_13: 0.8084; rho_23: 0.8579; discrepancy: 6276.819\n",
      "variance_1: 36.08; variance_2: 101.04; variance_3: 29.57; rho_12: 0.4262; rho_13: 0.7714; rho_23: 0.8877; discrepancy: 6277.436\n",
      "variance_1: 43.77; variance_2: 119.94; variance_3: 25.52; rho_12: 0.3991; rho_13: 0.8526; rho_23: 0.7694; discrepancy: 6277.150\n",
      "variance_1: 43.96; variance_2: 103.07; variance_3: 27.45; rho_12: 0.4096; rho_13: 0.9156; rho_23: 0.8239; discrepancy: 6276.307\n",
      "variance_1: 43.76; variance_2: 100.88; variance_3: 27.59; rho_12: 0.4298; rho_13: 0.9790; rho_23: 0.8304; discrepancy: 6276.924\n",
      "variance_1: 45.39; variance_2: 115.89; variance_3: 23.28; rho_12: 0.3786; rho_13: 0.9054; rho_23: 0.8594; discrepancy: 6277.090\n",
      "variance_1: 40.38; variance_2: 125.95; variance_3: 27.21; rho_12: 0.3582; rho_13: 0.9205; rho_23: 0.8113; discrepancy: 6276.674\n",
      "variance_1: 48.50; variance_2: 120.89; variance_3: 27.32; rho_12: 0.4047; rho_13: 0.8785; rho_23: 0.8275; discrepancy: 6275.661\n",
      "variance_1: 52.94; variance_2: 128.46; variance_3: 28.00; rho_12: 0.4254; rho_13: 0.8734; rho_23: 0.8302; discrepancy: 6275.366\n",
      "variance_1: 38.62; variance_2: 117.17; variance_3: 25.66; rho_12: 0.4345; rho_13: 0.8593; rho_23: 0.8244; discrepancy: 6275.688\n",
      "variance_1: 43.50; variance_2: 110.54; variance_3: 27.90; rho_12: 0.4038; rho_13: 0.9083; rho_23: 0.8996; discrepancy: 6275.573\n",
      "variance_1: 41.25; variance_2: 112.81; variance_3: 31.68; rho_12: 0.4327; rho_13: 0.8564; rho_23: 0.8230; discrepancy: 6275.503\n",
      "variance_1: 46.36; variance_2: 131.76; variance_3: 27.30; rho_12: 0.4189; rho_13: 0.9694; rho_23: 0.8129; discrepancy: 6275.819\n",
      "variance_1: 48.49; variance_2: 108.66; variance_3: 28.79; rho_12: 0.4834; rho_13: 0.8736; rho_23: 0.8601; discrepancy: 6274.451\n",
      "variance_1: 52.55; variance_2: 100.01; variance_3: 29.58; rho_12: 0.5460; rho_13: 0.8501; rho_23: 0.8845; discrepancy: 6274.662\n",
      "variance_1: 46.42; variance_2: 133.39; variance_3: 29.00; rho_12: 0.4567; rho_13: 0.8645; rho_23: 0.8595; discrepancy: 6273.814\n",
      "variance_1: 47.66; variance_2: 148.55; variance_3: 29.77; rho_12: 0.4803; rho_13: 0.8390; rho_23: 0.8773; discrepancy: 6273.390\n",
      "variance_1: 44.46; variance_2: 110.30; variance_3: 29.96; rho_12: 0.4678; rho_13: 0.7672; rho_23: 0.8919; discrepancy: 6275.779\n",
      "variance_1: 44.94; variance_2: 115.67; variance_3: 29.30; rho_12: 0.4556; rho_13: 0.8178; rho_23: 0.8722; discrepancy: 6274.788\n",
      "variance_1: 54.31; variance_2: 124.39; variance_3: 32.82; rho_12: 0.4592; rho_13: 0.8635; rho_23: 0.8964; discrepancy: 6274.992\n",
      "variance_1: 53.03; variance_2: 135.63; variance_3: 32.22; rho_12: 0.5084; rho_13: 0.7996; rho_23: 0.8201; discrepancy: 6275.093\n",
      "variance_1: 59.20; variance_2: 140.97; variance_3: 28.61; rho_12: 0.5046; rho_13: 0.8326; rho_23: 0.8957; discrepancy: 6274.786\n",
      "variance_1: 49.60; variance_2: 129.50; variance_3: 32.50; rho_12: 0.5384; rho_13: 0.8019; rho_23: 0.9104; discrepancy: 6274.101\n",
      "variance_1: 48.37; variance_2: 120.28; variance_3: 28.38; rho_12: 0.4655; rho_13: 0.8765; rho_23: 0.9506; discrepancy: 6274.168\n",
      "variance_1: 45.11; variance_2: 130.15; variance_3: 26.30; rho_12: 0.5167; rho_13: 0.8169; rho_23: 0.8923; discrepancy: 6274.222\n",
      "variance_1: 54.54; variance_2: 143.71; variance_3: 28.82; rho_12: 0.5408; rho_13: 0.8624; rho_23: 0.9233; discrepancy: 6273.479\n",
      "variance_1: 38.72; variance_2: 119.31; variance_3: 29.57; rho_12: 0.5037; rho_13: 0.8575; rho_23: 0.9089; discrepancy: 6273.495\n",
      "variance_1: 46.17; variance_2: 155.18; variance_3: 29.66; rho_12: 0.5317; rho_13: 0.8112; rho_23: 0.9608; discrepancy: 6273.624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance_1: 49.91; variance_2: 142.02; variance_3: 33.26; rho_12: 0.5034; rho_13: 0.8659; rho_23: 0.9514; discrepancy: 6273.876\n",
      "variance_1: 47.17; variance_2: 159.15; variance_3: 32.82; rho_12: 0.5673; rho_13: 0.8028; rho_23: 0.8935; discrepancy: 6273.498\n",
      "variance_1: 45.12; variance_2: 159.80; variance_3: 28.80; rho_12: 0.5039; rho_13: 0.8777; rho_23: 0.9280; discrepancy: 6272.570\n",
      "variance_1: 42.88; variance_2: 174.95; variance_3: 26.94; rho_12: 0.4867; rho_13: 0.9155; rho_23: 0.9368; discrepancy: 6272.759\n",
      "variance_1: 43.21; variance_2: 153.21; variance_3: 26.55; rho_12: 0.5391; rho_13: 0.8176; rho_23: 0.8792; discrepancy: 6273.732\n",
      "variance_1: 44.89; variance_2: 150.41; variance_3: 28.22; rho_12: 0.5302; rho_13: 0.8297; rho_23: 0.8972; discrepancy: 6273.082\n",
      "variance_1: 46.53; variance_2: 138.47; variance_3: 29.67; rho_12: 0.5103; rho_13: 0.8785; rho_23: 0.8486; discrepancy: 6273.064\n",
      "variance_1: 45.32; variance_2: 127.60; variance_3: 25.47; rho_12: 0.4558; rho_13: 0.9121; rho_23: 0.9010; discrepancy: 6274.143\n",
      "variance_1: 46.70; variance_2: 151.26; variance_3: 30.98; rho_12: 0.5394; rho_13: 0.8301; rho_23: 0.8953; discrepancy: 6272.943\n",
      "variance_1: 56.42; variance_2: 178.09; variance_3: 29.18; rho_12: 0.5313; rho_13: 0.8482; rho_23: 0.8810; discrepancy: 6273.605\n",
      "variance_1: 43.15; variance_2: 134.00; variance_3: 29.47; rho_12: 0.5106; rho_13: 0.8552; rho_23: 0.9019; discrepancy: 6272.926\n",
      "variance_1: 36.81; variance_2: 150.46; variance_3: 30.15; rho_12: 0.4841; rho_13: 0.8410; rho_23: 0.8595; discrepancy: 6273.623\n",
      "variance_1: 50.11; variance_2: 145.39; variance_3: 29.15; rho_12: 0.5266; rho_13: 0.8570; rho_23: 0.9073; discrepancy: 6273.003\n",
      "variance_1: 44.51; variance_2: 144.56; variance_3: 29.00; rho_12: 0.5601; rho_13: 0.8705; rho_23: 0.9155; discrepancy: 6272.315\n",
      "variance_1: 42.94; variance_2: 142.56; variance_3: 28.62; rho_12: 0.6000; rho_13: 0.8862; rho_23: 0.9347; discrepancy: 6272.139\n",
      "variance_1: 46.63; variance_2: 140.08; variance_3: 30.67; rho_12: 0.5334; rho_13: 0.8986; rho_23: 0.9080; discrepancy: 6272.537\n",
      "variance_1: 45.02; variance_2: 152.57; variance_3: 29.56; rho_12: 0.5610; rho_13: 0.8564; rho_23: 0.9765; discrepancy: 6272.851\n",
      "variance_1: 39.75; variance_2: 148.04; variance_3: 30.21; rho_12: 0.5562; rho_13: 0.8777; rho_23: 0.9408; discrepancy: 6272.323\n",
      "variance_1: 40.83; variance_2: 141.09; variance_3: 28.13; rho_12: 0.5490; rho_13: 0.9205; rho_23: 0.9680; discrepancy: 6272.484\n",
      "variance_1: 43.61; variance_2: 160.71; variance_3: 29.19; rho_12: 0.5906; rho_13: 0.9171; rho_23: 0.9834; discrepancy: 6272.341\n",
      "variance_1: 41.27; variance_2: 144.86; variance_3: 28.98; rho_12: 0.5500; rho_13: 0.9362; rho_23: 0.9111; discrepancy: 6272.138\n",
      "variance_1: 39.39; variance_2: 141.00; variance_3: 28.70; rho_12: 0.5446; rho_13: 0.9760; rho_23: 0.8784; discrepancy: 6272.813\n",
      "variance_1: 39.89; variance_2: 132.65; variance_3: 29.80; rho_12: 0.6225; rho_13: 0.9344; rho_23: 0.9540; discrepancy: 6272.118\n",
      "variance_1: 37.27; variance_2: 119.07; variance_3: 30.31; rho_12: 0.6817; rho_13: 0.9628; rho_23: 0.9670; discrepancy: 6272.762\n",
      "variance_1: 36.14; variance_2: 149.89; variance_3: 27.64; rho_12: 0.6227; rho_13: 0.9254; rho_23: 0.9893; discrepancy: 6272.614\n",
      "variance_1: 44.00; variance_2: 142.54; variance_3: 29.91; rho_12: 0.5557; rho_13: 0.9053; rho_23: 0.9284; discrepancy: 6272.164\n",
      "variance_1: 42.99; variance_2: 149.36; variance_3: 30.78; rho_12: 0.6094; rho_13: 0.8985; rho_23: 0.9161; discrepancy: 6271.927\n",
      "variance_1: 44.07; variance_2: 153.49; variance_3: 32.10; rho_12: 0.6396; rho_13: 0.8875; rho_23: 0.8902; discrepancy: 6272.266\n",
      "variance_1: 40.00; variance_2: 125.95; variance_3: 30.25; rho_12: 0.5740; rho_13: 0.8956; rho_23: 0.8783; discrepancy: 6272.506\n",
      "variance_1: 42.71; variance_2: 152.02; variance_3: 29.45; rho_12: 0.5864; rho_13: 0.9118; rho_23: 0.9571; discrepancy: 6272.029\n",
      "variance_1: 44.85; variance_2: 139.96; variance_3: 28.97; rho_12: 0.6185; rho_13: 0.9464; rho_23: 0.9263; discrepancy: 6272.183\n",
      "variance_1: 43.58; variance_2: 141.98; variance_3: 29.28; rho_12: 0.6029; rho_13: 0.9292; rho_23: 0.9299; discrepancy: 6271.978\n",
      "variance_1: 40.45; variance_2: 145.27; variance_3: 29.06; rho_12: 0.6347; rho_13: 0.9268; rho_23: 0.9393; discrepancy: 6271.916\n",
      "variance_1: 38.68; variance_2: 146.64; variance_3: 28.63; rho_12: 0.6742; rho_13: 0.9375; rho_23: 0.9448; discrepancy: 6272.187\n",
      "variance_1: 40.69; variance_2: 146.15; variance_3: 30.50; rho_12: 0.6020; rho_13: 0.9594; rho_23: 0.9346; discrepancy: 6272.178\n",
      "variance_1: 42.38; variance_2: 143.46; variance_3: 29.09; rho_12: 0.6005; rho_13: 0.9045; rho_23: 0.9346; discrepancy: 6271.953\n",
      "variance_1: 42.73; variance_2: 143.39; variance_3: 30.17; rho_12: 0.6688; rho_13: 0.8989; rho_23: 0.9659; discrepancy: 6272.423\n",
      "variance_1: 41.63; variance_2: 144.49; variance_3: 29.28; rho_12: 0.5797; rho_13: 0.9268; rho_23: 0.9248; discrepancy: 6271.931\n",
      "variance_1: 44.69; variance_2: 159.55; variance_3: 29.17; rho_12: 0.5821; rho_13: 0.8981; rho_23: 0.9133; discrepancy: 6271.901\n",
      "variance_1: 47.10; variance_2: 173.00; variance_3: 28.86; rho_12: 0.5619; rho_13: 0.8800; rho_23: 0.8929; discrepancy: 6272.153\n",
      "variance_1: 42.53; variance_2: 142.68; variance_3: 29.43; rho_12: 0.6167; rho_13: 0.9162; rho_23: 0.8956; discrepancy: 6271.991\n",
      "variance_1: 42.57; variance_2: 145.02; variance_3: 29.44; rho_12: 0.6091; rho_13: 0.9151; rho_23: 0.9110; discrepancy: 6271.892\n",
      "variance_1: 41.33; variance_2: 153.74; variance_3: 29.66; rho_12: 0.6022; rho_13: 0.8941; rho_23: 0.9164; discrepancy: 6271.865\n",
      "variance_1: 40.21; variance_2: 159.62; variance_3: 29.84; rho_12: 0.6019; rho_13: 0.8765; rho_23: 0.9097; discrepancy: 6272.006\n",
      "variance_1: 42.18; variance_2: 155.68; variance_3: 30.04; rho_12: 0.6052; rho_13: 0.9153; rho_23: 0.9057; discrepancy: 6271.770\n",
      "variance_1: 42.08; variance_2: 161.79; variance_3: 30.51; rho_12: 0.6076; rho_13: 0.9207; rho_23: 0.8912; discrepancy: 6271.764\n",
      "variance_1: 43.07; variance_2: 160.42; variance_3: 30.26; rho_12: 0.6353; rho_13: 0.8909; rho_23: 0.9043; discrepancy: 6272.003\n",
      "variance_1: 41.99; variance_2: 148.47; variance_3: 29.52; rho_12: 0.5936; rho_13: 0.9179; rho_23: 0.9197; discrepancy: 6271.831\n",
      "variance_1: 41.39; variance_2: 155.26; variance_3: 28.34; rho_12: 0.6004; rho_13: 0.9257; rho_23: 0.9142; discrepancy: 6271.793\n",
      "variance_1: 44.24; variance_2: 162.67; variance_3: 29.82; rho_12: 0.5636; rho_13: 0.8971; rho_23: 0.8826; discrepancy: 6271.920\n",
      "variance_1: 41.40; variance_2: 149.62; variance_3: 29.25; rho_12: 0.6169; rho_13: 0.9194; rho_23: 0.9251; discrepancy: 6271.819\n",
      "variance_1: 38.90; variance_2: 145.08; variance_3: 29.73; rho_12: 0.6279; rho_13: 0.9328; rho_23: 0.9126; discrepancy: 6271.909\n",
      "variance_1: 43.24; variance_2: 155.93; variance_3: 29.31; rho_12: 0.5935; rho_13: 0.9068; rho_23: 0.9131; discrepancy: 6271.816\n",
      "variance_1: 41.24; variance_2: 163.25; variance_3: 29.43; rho_12: 0.5957; rho_13: 0.9130; rho_23: 0.9156; discrepancy: 6271.695\n",
      "variance_1: 40.57; variance_2: 172.37; variance_3: 29.42; rho_12: 0.5889; rho_13: 0.9120; rho_23: 0.9180; discrepancy: 6271.658\n",
      "variance_1: 42.23; variance_2: 160.75; variance_3: 29.13; rho_12: 0.5981; rho_13: 0.9401; rho_23: 0.9107; discrepancy: 6271.766\n",
      "variance_1: 41.64; variance_2: 170.10; variance_3: 29.13; rho_12: 0.6082; rho_13: 0.9237; rho_23: 0.9044; discrepancy: 6271.660\n",
      "variance_1: 42.32; variance_2: 175.78; variance_3: 29.37; rho_12: 0.5820; rho_13: 0.9236; rho_23: 0.8920; discrepancy: 6271.642\n",
      "variance_1: 42.78; variance_2: 188.85; variance_3: 29.43; rho_12: 0.5645; rho_13: 0.9258; rho_23: 0.8755; discrepancy: 6271.662\n",
      "variance_1: 40.17; variance_2: 176.08; variance_3: 29.33; rho_12: 0.6015; rho_13: 0.9418; rho_23: 0.8970; discrepancy: 6271.644\n",
      "variance_1: 41.62; variance_2: 183.70; variance_3: 30.62; rho_12: 0.5951; rho_13: 0.9283; rho_23: 0.8903; discrepancy: 6271.614\n",
      "variance_1: 41.73; variance_2: 197.92; variance_3: 31.76; rho_12: 0.5924; rho_13: 0.9295; rho_23: 0.8783; discrepancy: 6271.688\n",
      "variance_1: 40.57; variance_2: 185.86; variance_3: 30.33; rho_12: 0.5963; rho_13: 0.9100; rho_23: 0.8870; discrepancy: 6271.605\n",
      "variance_1: 39.74; variance_2: 198.42; variance_3: 30.93; rho_12: 0.5955; rho_13: 0.8949; rho_23: 0.8752; discrepancy: 6271.712\n",
      "variance_1: 40.21; variance_2: 192.84; variance_3: 28.89; rho_12: 0.5831; rho_13: 0.9258; rho_23: 0.9050; discrepancy: 6271.554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance_1: 39.28; variance_2: 208.37; variance_3: 28.08; rho_12: 0.5709; rho_13: 0.9283; rho_23: 0.9119; discrepancy: 6271.634\n",
      "variance_1: 40.18; variance_2: 192.11; variance_3: 30.19; rho_12: 0.5741; rho_13: 0.9235; rho_23: 0.8920; discrepancy: 6271.574\n",
      "variance_1: 41.12; variance_2: 196.42; variance_3: 30.15; rho_12: 0.5885; rho_13: 0.9390; rho_23: 0.8698; discrepancy: 6271.632\n",
      "variance_1: 41.84; variance_2: 199.49; variance_3: 30.53; rho_12: 0.5715; rho_13: 0.9082; rho_23: 0.8817; discrepancy: 6271.575\n",
      "variance_1: 39.53; variance_2: 207.70; variance_3: 30.87; rho_12: 0.5875; rho_13: 0.9212; rho_23: 0.8832; discrepancy: 6271.564\n",
      "variance_1: 40.19; variance_2: 190.82; variance_3: 30.32; rho_12: 0.5808; rho_13: 0.9000; rho_23: 0.9099; discrepancy: 6271.650\n",
      "variance_1: 40.89; variance_2: 195.02; variance_3: 30.20; rho_12: 0.5865; rho_13: 0.9292; rho_23: 0.8799; discrepancy: 6271.563\n",
      "variance_1: 39.45; variance_2: 207.31; variance_3: 29.71; rho_12: 0.5713; rho_13: 0.9110; rho_23: 0.8860; discrepancy: 6271.554\n",
      "variance_1: 40.13; variance_2: 212.29; variance_3: 29.80; rho_12: 0.5617; rho_13: 0.9297; rho_23: 0.8890; discrepancy: 6271.545\n",
      "variance_1: 39.90; variance_2: 225.51; variance_3: 29.53; rho_12: 0.5443; rho_13: 0.9395; rho_23: 0.8900; discrepancy: 6271.654\n",
      "variance_1: 38.29; variance_2: 202.93; variance_3: 29.36; rho_12: 0.5833; rho_13: 0.9386; rho_23: 0.8967; discrepancy: 6271.590\n",
      "variance_1: 40.95; variance_2: 200.35; variance_3: 30.24; rho_12: 0.5744; rho_13: 0.9158; rho_23: 0.8854; discrepancy: 6271.537\n",
      "variance_1: 40.21; variance_2: 213.06; variance_3: 29.71; rho_12: 0.5807; rho_13: 0.9208; rho_23: 0.8841; discrepancy: 6271.491\n",
      "variance_1: 40.23; variance_2: 223.53; variance_3: 29.47; rho_12: 0.5841; rho_13: 0.9194; rho_23: 0.8802; discrepancy: 6271.485\n",
      "variance_1: 41.09; variance_2: 202.75; variance_3: 28.57; rho_12: 0.5662; rho_13: 0.9224; rho_23: 0.8919; discrepancy: 6271.563\n",
      "variance_1: 39.80; variance_2: 218.00; variance_3: 28.69; rho_12: 0.5604; rho_13: 0.9121; rho_23: 0.8993; discrepancy: 6271.585\n",
      "variance_1: 40.62; variance_2: 200.76; variance_3: 29.82; rho_12: 0.5800; rho_13: 0.9249; rho_23: 0.8847; discrepancy: 6271.519\n",
      "variance_1: 39.43; variance_2: 209.61; variance_3: 30.74; rho_12: 0.5854; rho_13: 0.9198; rho_23: 0.8849; discrepancy: 6271.554\n",
      "variance_1: 41.07; variance_2: 205.82; variance_3: 29.94; rho_12: 0.5849; rho_13: 0.9341; rho_23: 0.8904; discrepancy: 6271.514\n",
      "variance_1: 41.63; variance_2: 202.25; variance_3: 28.64; rho_12: 0.5707; rho_13: 0.9301; rho_23: 0.8934; discrepancy: 6271.560\n",
      "variance_1: 39.98; variance_2: 207.77; variance_3: 30.22; rho_12: 0.5817; rho_13: 0.9224; rho_23: 0.8870; discrepancy: 6271.513\n",
      "variance_1: 40.78; variance_2: 224.00; variance_3: 30.94; rho_12: 0.5725; rho_13: 0.9230; rho_23: 0.8672; discrepancy: 6271.553\n",
      "variance_1: 40.64; variance_2: 216.21; variance_3: 30.43; rho_12: 0.5751; rho_13: 0.9237; rho_23: 0.8767; discrepancy: 6271.513\n",
      "variance_1: 41.03; variance_2: 205.86; variance_3: 30.24; rho_12: 0.5984; rho_13: 0.9171; rho_23: 0.8792; discrepancy: 6271.538\n",
      "variance_1: 40.81; variance_2: 207.47; variance_3: 30.13; rho_12: 0.5892; rho_13: 0.9202; rho_23: 0.8816; discrepancy: 6271.508\n",
      "variance_1: 40.16; variance_2: 220.17; variance_3: 29.77; rho_12: 0.5906; rho_13: 0.9325; rho_23: 0.8814; discrepancy: 6271.489\n",
      "variance_1: 40.34; variance_2: 226.23; variance_3: 30.16; rho_12: 0.5885; rho_13: 0.9258; rho_23: 0.8810; discrepancy: 6271.477\n",
      "variance_1: 40.21; variance_2: 238.96; variance_3: 30.33; rho_12: 0.5928; rho_13: 0.9263; rho_23: 0.8792; discrepancy: 6271.481\n",
      "variance_1: 39.65; variance_2: 227.97; variance_3: 30.12; rho_12: 0.5848; rho_13: 0.9139; rho_23: 0.8722; discrepancy: 6271.521\n",
      "variance_1: 40.71; variance_2: 211.36; variance_3: 29.99; rho_12: 0.5849; rho_13: 0.9291; rho_23: 0.8859; discrepancy: 6271.492\n",
      "variance_1: 40.98; variance_2: 227.22; variance_3: 29.76; rho_12: 0.5891; rho_13: 0.9279; rho_23: 0.8753; discrepancy: 6271.483\n",
      "variance_1: 40.44; variance_2: 222.45; variance_3: 29.34; rho_12: 0.6003; rho_13: 0.9279; rho_23: 0.8851; discrepancy: 6271.498\n",
      "variance_1: 40.15; variance_2: 236.18; variance_3: 29.37; rho_12: 0.5899; rho_13: 0.9339; rho_23: 0.8813; discrepancy: 6271.478\n",
      "variance_1: 40.42; variance_2: 225.78; variance_3: 30.17; rho_12: 0.5754; rho_13: 0.9283; rho_23: 0.8766; discrepancy: 6271.491\n",
      "variance_1: 40.04; variance_2: 241.68; variance_3: 29.58; rho_12: 0.5876; rho_13: 0.9269; rho_23: 0.8727; discrepancy: 6271.482\n",
      "variance_1: 40.22; variance_2: 232.55; variance_3: 29.20; rho_12: 0.6012; rho_13: 0.9272; rho_23: 0.8808; discrepancy: 6271.511\n",
      "variance_1: 40.37; variance_2: 227.48; variance_3: 29.93; rho_12: 0.5818; rho_13: 0.9280; rho_23: 0.8776; discrepancy: 6271.476\n",
      "variance_1: 40.54; variance_2: 240.60; variance_3: 29.66; rho_12: 0.5831; rho_13: 0.9215; rho_23: 0.8746; discrepancy: 6271.469\n",
      "variance_1: 40.73; variance_2: 250.81; variance_3: 29.60; rho_12: 0.5794; rho_13: 0.9160; rho_23: 0.8713; discrepancy: 6271.480\n",
      "variance_1: 40.58; variance_2: 242.93; variance_3: 30.01; rho_12: 0.5893; rho_13: 0.9353; rho_23: 0.8740; discrepancy: 6271.486\n",
      "variance_1: 40.31; variance_2: 228.38; variance_3: 29.61; rho_12: 0.5854; rho_13: 0.9234; rho_23: 0.8786; discrepancy: 6271.474\n",
      "variance_1: 39.61; variance_2: 239.63; variance_3: 29.67; rho_12: 0.5831; rho_13: 0.9253; rho_23: 0.8801; discrepancy: 6271.474\n",
      "variance_1: 40.40; variance_2: 224.49; variance_3: 29.88; rho_12: 0.5830; rho_13: 0.9258; rho_23: 0.8850; discrepancy: 6271.468\n",
      "variance_1: 40.57; variance_2: 215.89; variance_3: 30.03; rho_12: 0.5807; rho_13: 0.9252; rho_23: 0.8912; discrepancy: 6271.482\n",
      "variance_1: 40.38; variance_2: 226.08; variance_3: 30.27; rho_12: 0.5784; rho_13: 0.9160; rho_23: 0.8777; discrepancy: 6271.490\n",
      "variance_1: 40.20; variance_2: 233.66; variance_3: 29.59; rho_12: 0.5870; rho_13: 0.9295; rho_23: 0.8804; discrepancy: 6271.469\n",
      "variance_1: 40.13; variance_2: 238.52; variance_3: 29.28; rho_12: 0.5793; rho_13: 0.9253; rho_23: 0.8778; discrepancy: 6271.472\n",
      "variance_1: 40.03; variance_2: 240.95; variance_3: 29.30; rho_12: 0.5851; rho_13: 0.9222; rho_23: 0.8813; discrepancy: 6271.476\n",
      "variance_1: 40.28; variance_2: 230.84; variance_3: 29.77; rho_12: 0.5827; rho_13: 0.9266; rho_23: 0.8785; discrepancy: 6271.469\n",
      "variance_1: 40.07; variance_2: 240.87; variance_3: 29.68; rho_12: 0.5807; rho_13: 0.9279; rho_23: 0.8802; discrepancy: 6271.462\n",
      "variance_1: 39.95; variance_2: 247.11; variance_3: 29.71; rho_12: 0.5783; rho_13: 0.9302; rho_23: 0.8810; discrepancy: 6271.464\n",
      "variance_1: 40.94; variance_2: 230.02; variance_3: 29.62; rho_12: 0.5822; rho_13: 0.9269; rho_23: 0.8788; discrepancy: 6271.466\n",
      "variance_1: 40.68; variance_2: 228.31; variance_3: 30.12; rho_12: 0.5870; rho_13: 0.9274; rho_23: 0.8814; discrepancy: 6271.470\n",
      "variance_1: 40.54; variance_2: 230.86; variance_3: 29.91; rho_12: 0.5850; rho_13: 0.9269; rho_23: 0.8805; discrepancy: 6271.465\n",
      "variance_1: 40.27; variance_2: 222.98; variance_3: 29.83; rho_12: 0.5837; rho_13: 0.9330; rho_23: 0.8865; discrepancy: 6271.479\n",
      "variance_1: 40.47; variance_2: 236.19; variance_3: 29.70; rho_12: 0.5833; rho_13: 0.9244; rho_23: 0.8776; discrepancy: 6271.464\n",
      "variance_1: 40.59; variance_2: 234.52; variance_3: 29.69; rho_12: 0.5844; rho_13: 0.9272; rho_23: 0.8823; discrepancy: 6271.459\n",
      "variance_1: 40.75; variance_2: 236.36; variance_3: 29.64; rho_12: 0.5853; rho_13: 0.9275; rho_23: 0.8842; discrepancy: 6271.457\n",
      "variance_1: 40.85; variance_2: 232.60; variance_3: 29.88; rho_12: 0.5795; rho_13: 0.9237; rho_23: 0.8817; discrepancy: 6271.459\n",
      "variance_1: 40.81; variance_2: 244.48; variance_3: 29.59; rho_12: 0.5823; rho_13: 0.9266; rho_23: 0.8760; discrepancy: 6271.461\n",
      "variance_1: 40.23; variance_2: 243.76; variance_3: 29.85; rho_12: 0.5831; rho_13: 0.9255; rho_23: 0.8813; discrepancy: 6271.458\n",
      "variance_1: 40.52; variance_2: 247.23; variance_3: 29.54; rho_12: 0.5797; rho_13: 0.9250; rho_23: 0.8798; discrepancy: 6271.456\n",
      "variance_1: 40.51; variance_2: 255.41; variance_3: 29.36; rho_12: 0.5770; rho_13: 0.9240; rho_23: 0.8795; discrepancy: 6271.460\n",
      "variance_1: 40.61; variance_2: 245.57; variance_3: 29.70; rho_12: 0.5802; rho_13: 0.9277; rho_23: 0.8834; discrepancy: 6271.453\n",
      "variance_1: 40.67; variance_2: 250.26; variance_3: 29.70; rho_12: 0.5787; rho_13: 0.9293; rho_23: 0.8864; discrepancy: 6271.455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance_1: 41.18; variance_2: 242.47; variance_3: 29.73; rho_12: 0.5827; rho_13: 0.9240; rho_23: 0.8820; discrepancy: 6271.454\n",
      "variance_1: 40.57; variance_2: 238.18; variance_3: 29.86; rho_12: 0.5812; rho_13: 0.9245; rho_23: 0.8882; discrepancy: 6271.456\n",
      "variance_1: 40.43; variance_2: 251.92; variance_3: 29.56; rho_12: 0.5846; rho_13: 0.9277; rho_23: 0.8846; discrepancy: 6271.458\n",
      "variance_1: 41.12; variance_2: 243.48; variance_3: 29.49; rho_12: 0.5814; rho_13: 0.9267; rho_23: 0.8861; discrepancy: 6271.455\n",
      "variance_1: 41.15; variance_2: 232.51; variance_3: 29.76; rho_12: 0.5789; rho_13: 0.9241; rho_23: 0.8833; discrepancy: 6271.457\n",
      "variance_1: 40.97; variance_2: 237.36; variance_3: 29.71; rho_12: 0.5803; rho_13: 0.9250; rho_23: 0.8836; discrepancy: 6271.454\n",
      "variance_1: 40.91; variance_2: 248.41; variance_3: 29.70; rho_12: 0.5766; rho_13: 0.9234; rho_23: 0.8835; discrepancy: 6271.451\n",
      "variance_1: 40.99; variance_2: 254.43; variance_3: 29.73; rho_12: 0.5722; rho_13: 0.9214; rho_23: 0.8831; discrepancy: 6271.454\n",
      "variance_1: 41.20; variance_2: 249.99; variance_3: 29.43; rho_12: 0.5792; rho_13: 0.9261; rho_23: 0.8780; discrepancy: 6271.459\n",
      "variance_1: 40.73; variance_2: 241.14; variance_3: 29.75; rho_12: 0.5807; rho_13: 0.9249; rho_23: 0.8856; discrepancy: 6271.452\n",
      "variance_1: 41.32; variance_2: 238.92; variance_3: 29.82; rho_12: 0.5810; rho_13: 0.9256; rho_23: 0.8883; discrepancy: 6271.455\n",
      "variance_1: 40.78; variance_2: 241.14; variance_3: 29.98; rho_12: 0.5791; rho_13: 0.9235; rho_23: 0.8827; discrepancy: 6271.454\n",
      "variance_1: 40.41; variance_2: 246.45; variance_3: 29.71; rho_12: 0.5789; rho_13: 0.9239; rho_23: 0.8787; discrepancy: 6271.457\n",
      "variance_1: 41.09; variance_2: 240.80; variance_3: 29.79; rho_12: 0.5804; rho_13: 0.9252; rho_23: 0.8859; discrepancy: 6271.452\n",
      "variance_1: 41.05; variance_2: 244.11; variance_3: 29.48; rho_12: 0.5813; rho_13: 0.9266; rho_23: 0.8853; discrepancy: 6271.455\n",
      "variance_1: 40.85; variance_2: 241.88; variance_3: 29.86; rho_12: 0.5796; rho_13: 0.9243; rho_23: 0.8833; discrepancy: 6271.452\n",
      "variance_1: 40.53; variance_2: 242.58; variance_3: 29.77; rho_12: 0.5766; rho_13: 0.9261; rho_23: 0.8865; discrepancy: 6271.456\n",
      "variance_1: 41.02; variance_2: 242.50; variance_3: 29.74; rho_12: 0.5812; rho_13: 0.9246; rho_23: 0.8831; discrepancy: 6271.452\n",
      "variance_1: 40.76; variance_2: 249.40; variance_3: 29.80; rho_12: 0.5793; rho_13: 0.9250; rho_23: 0.8847; discrepancy: 6271.451\n",
      "variance_1: 41.18; variance_2: 242.47; variance_3: 29.85; rho_12: 0.5790; rho_13: 0.9215; rho_23: 0.8852; discrepancy: 6271.453\n",
      "variance_1: 41.04; variance_2: 243.25; variance_3: 29.81; rho_12: 0.5793; rho_13: 0.9230; rho_23: 0.8848; discrepancy: 6271.452\n",
      "variance_1: 41.16; variance_2: 247.61; variance_3: 29.81; rho_12: 0.5781; rho_13: 0.9236; rho_23: 0.8828; discrepancy: 6271.451\n",
      "variance_1: 41.38; variance_2: 250.85; variance_3: 29.84; rho_12: 0.5768; rho_13: 0.9230; rho_23: 0.8814; discrepancy: 6271.452\n",
      "variance_1: 40.82; variance_2: 250.22; variance_3: 29.78; rho_12: 0.5776; rho_13: 0.9228; rho_23: 0.8815; discrepancy: 6271.451\n",
      "variance_1: 41.06; variance_2: 251.91; variance_3: 29.69; rho_12: 0.5777; rho_13: 0.9232; rho_23: 0.8834; discrepancy: 6271.451\n",
      "variance_1: 40.90; variance_2: 254.43; variance_3: 29.79; rho_12: 0.5750; rho_13: 0.9225; rho_23: 0.8838; discrepancy: 6271.453\n",
      "variance_1: 40.99; variance_2: 245.48; variance_3: 29.75; rho_12: 0.5796; rho_13: 0.9240; rho_23: 0.8833; discrepancy: 6271.451\n",
      "variance_1: 40.87; variance_2: 254.43; variance_3: 29.70; rho_12: 0.5770; rho_13: 0.9244; rho_23: 0.8816; discrepancy: 6271.451\n",
      "variance_1: 41.09; variance_2: 248.87; variance_3: 29.71; rho_12: 0.5785; rho_13: 0.9251; rho_23: 0.8849; discrepancy: 6271.451\n",
      "variance_1: 41.26; variance_2: 249.50; variance_3: 29.66; rho_12: 0.5766; rho_13: 0.9229; rho_23: 0.8818; discrepancy: 6271.452\n",
      "variance_1: 40.89; variance_2: 249.43; variance_3: 29.76; rho_12: 0.5786; rho_13: 0.9245; rho_23: 0.8840; discrepancy: 6271.451\n",
      "variance_1: 40.91; variance_2: 246.16; variance_3: 29.79; rho_12: 0.5784; rho_13: 0.9251; rho_23: 0.8832; discrepancy: 6271.451\n",
      "variance_1: 41.06; variance_2: 248.92; variance_3: 29.81; rho_12: 0.5802; rho_13: 0.9255; rho_23: 0.8831; discrepancy: 6271.451\n",
      "variance_1: 41.17; variance_2: 241.06; variance_3: 29.84; rho_12: 0.5808; rho_13: 0.9249; rho_23: 0.8855; discrepancy: 6271.452\n",
      "variance_1: 40.94; variance_2: 251.09; variance_3: 29.74; rho_12: 0.5779; rho_13: 0.9245; rho_23: 0.8826; discrepancy: 6271.451\n",
      "variance_1: 40.89; variance_2: 247.37; variance_3: 29.85; rho_12: 0.5791; rho_13: 0.9240; rho_23: 0.8814; discrepancy: 6271.451\n",
      "variance_1: 41.04; variance_2: 248.49; variance_3: 29.74; rho_12: 0.5787; rho_13: 0.9248; rho_23: 0.8840; discrepancy: 6271.451\n",
      "variance_1: 41.01; variance_2: 251.75; variance_3: 29.80; rho_12: 0.5777; rho_13: 0.9253; rho_23: 0.8833; discrepancy: 6271.451\n",
      "variance_1: 40.79; variance_2: 251.00; variance_3: 29.73; rho_12: 0.5790; rho_13: 0.9263; rho_23: 0.8839; discrepancy: 6271.451\n",
      "variance_1: 41.07; variance_2: 248.46; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9243; rho_23: 0.8831; discrepancy: 6271.450\n",
      "variance_1: 41.09; variance_2: 253.21; variance_3: 29.76; rho_12: 0.5787; rho_13: 0.9245; rho_23: 0.8834; discrepancy: 6271.451\n",
      "variance_1: 40.96; variance_2: 247.93; variance_3: 29.78; rho_12: 0.5785; rho_13: 0.9250; rho_23: 0.8833; discrepancy: 6271.451\n",
      "variance_1: 40.91; variance_2: 250.13; variance_3: 29.73; rho_12: 0.5764; rho_13: 0.9240; rho_23: 0.8836; discrepancy: 6271.451\n",
      "variance_1: 41.02; variance_2: 249.22; variance_3: 29.79; rho_12: 0.5792; rho_13: 0.9251; rho_23: 0.8832; discrepancy: 6271.450\n",
      "variance_1: 41.13; variance_2: 249.55; variance_3: 29.78; rho_12: 0.5782; rho_13: 0.9252; rho_23: 0.8825; discrepancy: 6271.451\n",
      "variance_1: 41.07; variance_2: 249.52; variance_3: 29.78; rho_12: 0.5783; rho_13: 0.9250; rho_23: 0.8829; discrepancy: 6271.450\n",
      "variance_1: 41.02; variance_2: 246.48; variance_3: 29.74; rho_12: 0.5793; rho_13: 0.9243; rho_23: 0.8831; discrepancy: 6271.451\n",
      "variance_1: 41.01; variance_2: 250.43; variance_3: 29.78; rho_12: 0.5781; rho_13: 0.9250; rho_23: 0.8832; discrepancy: 6271.450\n",
      "variance_1: 40.98; variance_2: 250.39; variance_3: 29.81; rho_12: 0.5781; rho_13: 0.9248; rho_23: 0.8821; discrepancy: 6271.450\n",
      "variance_1: 40.95; variance_2: 251.34; variance_3: 29.85; rho_12: 0.5779; rho_13: 0.9248; rho_23: 0.8811; discrepancy: 6271.451\n",
      "variance_1: 41.10; variance_2: 247.56; variance_3: 29.84; rho_12: 0.5789; rho_13: 0.9252; rho_23: 0.8834; discrepancy: 6271.451\n",
      "variance_1: 40.98; variance_2: 250.21; variance_3: 29.76; rho_12: 0.5782; rho_13: 0.9247; rho_23: 0.8828; discrepancy: 6271.450\n",
      "variance_1: 41.09; variance_2: 251.49; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9247; rho_23: 0.8825; discrepancy: 6271.450\n",
      "variance_1: 40.98; variance_2: 251.96; variance_3: 29.78; rho_12: 0.5784; rho_13: 0.9255; rho_23: 0.8825; discrepancy: 6271.450\n",
      "variance_1: 41.05; variance_2: 249.33; variance_3: 29.79; rho_12: 0.5784; rho_13: 0.9246; rho_23: 0.8829; discrepancy: 6271.450\n",
      "variance_1: 40.95; variance_2: 248.22; variance_3: 29.78; rho_12: 0.5785; rho_13: 0.9251; rho_23: 0.8832; discrepancy: 6271.450\n",
      "variance_1: 41.05; variance_2: 250.67; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9248; rho_23: 0.8827; discrepancy: 6271.450\n",
      "variance_1: 41.03; variance_2: 250.96; variance_3: 29.78; rho_12: 0.5772; rho_13: 0.9245; rho_23: 0.8823; discrepancy: 6271.450\n",
      "variance_1: 40.97; variance_2: 251.15; variance_3: 29.80; rho_12: 0.5778; rho_13: 0.9245; rho_23: 0.8824; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.47; variance_3: 29.80; rho_12: 0.5779; rho_13: 0.9242; rho_23: 0.8818; discrepancy: 6271.450\n",
      "variance_1: 40.99; variance_2: 249.78; variance_3: 29.80; rho_12: 0.5790; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.04; variance_3: 29.79; rho_12: 0.5787; rho_13: 0.9251; rho_23: 0.8833; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.36; variance_3: 29.79; rho_12: 0.5781; rho_13: 0.9245; rho_23: 0.8822; discrepancy: 6271.450\n",
      "variance_1: 41.03; variance_2: 250.11; variance_3: 29.77; rho_12: 0.5785; rho_13: 0.9244; rho_23: 0.8831; discrepancy: 6271.450\n",
      "variance_1: 40.99; variance_2: 250.32; variance_3: 29.80; rho_12: 0.5782; rho_13: 0.9247; rho_23: 0.8823; discrepancy: 6271.450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance_1: 41.05; variance_2: 249.08; variance_3: 29.78; rho_12: 0.5789; rho_13: 0.9248; rho_23: 0.8827; discrepancy: 6271.450\n",
      "variance_1: 40.99; variance_2: 250.63; variance_3: 29.79; rho_12: 0.5781; rho_13: 0.9246; rho_23: 0.8825; discrepancy: 6271.450\n",
      "variance_1: 41.04; variance_2: 250.73; variance_3: 29.78; rho_12: 0.5774; rho_13: 0.9246; rho_23: 0.8825; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.02; variance_3: 29.79; rho_12: 0.5786; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 40.96; variance_2: 251.40; variance_3: 29.79; rho_12: 0.5782; rho_13: 0.9247; rho_23: 0.8821; discrepancy: 6271.450\n",
      "variance_1: 41.03; variance_2: 249.85; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8827; discrepancy: 6271.450\n",
      "variance_1: 40.94; variance_2: 249.79; variance_3: 29.79; rho_12: 0.5782; rho_13: 0.9245; rho_23: 0.8824; discrepancy: 6271.450\n",
      "variance_1: 41.03; variance_2: 250.45; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.03; variance_2: 250.34; variance_3: 29.82; rho_12: 0.5784; rho_13: 0.9245; rho_23: 0.8822; discrepancy: 6271.450\n",
      "variance_1: 40.99; variance_2: 250.24; variance_3: 29.78; rho_12: 0.5782; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.14; variance_3: 29.79; rho_12: 0.5785; rho_13: 0.9248; rho_23: 0.8829; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.20; variance_3: 29.79; rho_12: 0.5784; rho_13: 0.9247; rho_23: 0.8827; discrepancy: 6271.450\n",
      "variance_1: 41.02; variance_2: 250.14; variance_3: 29.78; rho_12: 0.5784; rho_13: 0.9246; rho_23: 0.8829; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.28; variance_3: 29.80; rho_12: 0.5783; rho_13: 0.9247; rho_23: 0.8825; discrepancy: 6271.450\n",
      "variance_1: 40.98; variance_2: 250.75; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9247; rho_23: 0.8825; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.08; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.61; variance_3: 29.78; rho_12: 0.5779; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.16; variance_3: 29.79; rho_12: 0.5784; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.02; variance_2: 249.84; variance_3: 29.79; rho_12: 0.5786; rho_13: 0.9248; rho_23: 0.8827; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.43; variance_3: 29.79; rho_12: 0.5782; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.02; variance_2: 250.29; variance_3: 29.80; rho_12: 0.5784; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.25; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 40.98; variance_2: 250.01; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.34; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.32; variance_3: 29.79; rho_12: 0.5782; rho_13: 0.9246; rho_23: 0.8824; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.23; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9247; rho_23: 0.8827; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.22; variance_3: 29.78; rho_12: 0.5784; rho_13: 0.9246; rho_23: 0.8827; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.26; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9247; rho_23: 0.8825; discrepancy: 6271.450\n",
      "variance_1: 40.99; variance_2: 250.48; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9247; rho_23: 0.8825; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.50; variance_3: 29.79; rho_12: 0.5781; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.25; variance_3: 29.79; rho_12: 0.5784; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 40.99; variance_2: 250.29; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.33; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.10; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.39; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.38; variance_3: 29.80; rho_12: 0.5783; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.34; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.17; variance_3: 29.79; rho_12: 0.5784; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.37; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.42; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8825; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.37; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8825; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.42; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.50; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.31; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.33; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.46; variance_3: 29.79; rho_12: 0.5782; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.37; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.37; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.42; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.28; variance_3: 29.79; rho_12: 0.5784; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.34; variance_3: 29.79; rho_12: 0.5784; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.26; variance_3: 29.79; rho_12: 0.5784; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.38; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.35; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.44; variance_3: 29.79; rho_12: 0.5782; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.40; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.39; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.42; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.49; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.35; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.40; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9247; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.39; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.35; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.37; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.33; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance_1: 41.01; variance_2: 250.40; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.39; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.41; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8825; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.36; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.37; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.38; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.36; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.38; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.39; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.37; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.35; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.38; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.38; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.40; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.36; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.39; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.42; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.37; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.35; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.39; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.39; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.38; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.38; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.38; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.38; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.38; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.01; variance_2: 250.38; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.38; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.38; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.38; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.37; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.38; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.38; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.36; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.37; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.38; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n",
      "variance_1: 41.00; variance_2: 250.37; variance_3: 29.79; rho_12: 0.5783; rho_13: 0.9246; rho_23: 0.8826; discrepancy: 6271.450\n"
     ]
    }
   ],
   "source": [
    "train_parameter = optimize_parameter(winners, losers, surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " {'variance_1': 41.00449449931838,\n",
       "  'variance_2': 250.37152719311047,\n",
       "  'variance_3': 29.791091918852644,\n",
       "  'rho_12': 0.5782998894980254,\n",
       "  'rho_13': 0.9246322686298704,\n",
       "  'rho_23': 0.8825783972979642})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cov = np.array([[train_parameter[1]['variance_1'],train_parameter[1]['rho_12']*np.sqrt(train_parameter[1]['variance_1']*train_parameter[1]['variance_2']),train_parameter[1]['rho_13']*np.sqrt(train_parameter[1]['variance_1']*train_parameter[1]['variance_3'])],\n",
    "          [train_parameter[1]['rho_12']*np.sqrt(train_parameter[1]['variance_1']*train_parameter[1]['variance_2']),train_parameter[1]['variance_2'],train_parameter[1]['rho_23']*np.sqrt(train_parameter[1]['variance_2']*train_parameter[1]['variance_3'])],\n",
    "          [train_parameter[1]['rho_13']*np.sqrt(train_parameter[1]['variance_1']*train_parameter[1]['variance_3']),train_parameter[1]['rho_23']*np.sqrt(train_parameter[1]['variance_2']*train_parameter[1]['variance_3']),train_parameter[1]['variance_3']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_mat = pd.DataFrame(train_cov,columns=[encode_marks(Train['surface'])[1]],index = encode_marks(Train['surface'])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "估計超參數如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Clay</th>\n",
       "      <th>Grass</th>\n",
       "      <th>Hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Clay</th>\n",
       "      <td>41.004494</td>\n",
       "      <td>58.595101</td>\n",
       "      <td>32.316773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grass</th>\n",
       "      <td>58.595101</td>\n",
       "      <td>250.371527</td>\n",
       "      <td>76.223515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hard</th>\n",
       "      <td>32.316773</td>\n",
       "      <td>76.223515</td>\n",
       "      <td>29.791092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Clay       Grass       Hard\n",
       "Clay   41.004494   58.595101  32.316773\n",
       "Grass  58.595101  250.371527  76.223515\n",
       "Hard   32.316773   76.223515  29.791092"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. hard的變異數明顯比較小，可能跟hard比賽的次數較多有關係 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surface_accuracy(train, to_use, beta, variance_1, variance_2, variance_3, rho_12, rho_13, rho_23):\n",
    "    '''\n",
    "    Args:\n",
    "    train: training dataset\n",
    "    to_use: total dataset\n",
    "    surface: The array of surfaces for each of N contest, of shape [N, 3]\n",
    "    beta: The uncontral variances of the game\n",
    "    variance_1: The initial variance of surface 1\n",
    "    variance_2: The initial variance of surface 2\n",
    "    variance_3: The initial variance of surface 3\n",
    "    rho_12: The initial correlation coefficient between surface 1 and surface 2\n",
    "    rho_13: The initial correlation coefficient between surface 1 and surface 3\n",
    "    rho_23: The initial correlation coefficient between surface 2 and surface 3\n",
    "    Return:\n",
    "    accuracy: The accuracy of the model\n",
    "    '''\n",
    "    to_use_winners = to_use[['winner1_name','winner2_name']]\n",
    "    to_use_losers = to_use[['loser1_name','loser2_name']]\n",
    "    to_use_surface = encode_marks(to_use['surface'])[0]\n",
    "    # 1. calculate rating \n",
    "    to_use_player_rating = calculate_ratings(winners= to_use_winners,\n",
    "                                             losers= to_use_losers,\n",
    "                                             surface= to_use_surface,\n",
    "                                             beta= beta,\n",
    "                                             variance_1=variance_1,\n",
    "                                             variance_2= variance_2,\n",
    "                                             variance_3=variance_3,\n",
    "                                             rho_12= rho_12,\n",
    "                                             rho_13= rho_13,\n",
    "                                             rho_23= rho_23)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # 2. calculate the test accuracy \n",
    "    for game in np.arange(train.shape[0], to_use.shape[0]):\n",
    "        # get the current winners & losers\n",
    "        cur_winner_1 , cur_winner_2 = to_use_winners['winner1_name'][game], to_use_winners['winner2_name'][game]\n",
    "        cur_loser_1, cur_loser_2 = to_use_losers['loser1_name'][game], to_use_losers['loser2_name'][game]\n",
    "        # get the current surface\n",
    "        cur_surface = to_use_surface[game]\n",
    "        # get the winner & loser rating\n",
    "        cur_player_rating = to_use_player_rating[0][game]\n",
    "        cur_winner_1_rating, cur_winner_2_rating = cur_player_rating[cur_winner_1], cur_player_rating[cur_winner_2]\n",
    "        cur_loser_1_rating, cur_loser_2_rating = cur_player_rating[cur_loser_1], cur_player_rating[cur_loser_2]\n",
    "        # get the team rating\n",
    "        winner_team = cur_winner_1_rating + cur_winner_2_rating\n",
    "        loser_team = cur_loser_1_rating + cur_loser_2_rating\n",
    "        # get the surface\n",
    "        winner_surface = cur_surface.reshape((1,3)).dot(winner_team)\n",
    "        loser_surface = cur_surface.reshape((1,3)).dot(loser_team)\n",
    "        # check whether winner > loser\n",
    "        if winner_surface> loser_surface:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_accuracy = surface_accuracy(Train, \n",
    "                               to_use, \n",
    "                               3**2, \n",
    "                               train_parameter[1]['variance_1'], \n",
    "                               train_parameter[1]['variance_2'], \n",
    "                               train_parameter[1]['variance_3'], \n",
    "                               train_parameter[1]['rho_12'], \n",
    "                               train_parameter[1]['rho_13'],\n",
    "                               train_parameter[1]['rho_23'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model accuracy = 63.282769350447296 %\n"
     ]
    }
   ],
   "source": [
    "print('The model accuracy = {} %'.format(my_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## each surface accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def each_surface_accuracy(train, to_use, beta, variance_1, variance_2, variance_3, rho_12, rho_13, rho_23):\n",
    "    '''\n",
    "    Args:\n",
    "    train: training dataset\n",
    "    to_use: total dataset\n",
    "    surface: The array of surfaces for each of N contest, of shape [N, 3]\n",
    "    beta: The uncontral variances of the game\n",
    "    variance_1: The initial variance of surface 1\n",
    "    variance_2: The initial variance of surface 2\n",
    "    variance_3: The initial variance of surface 3\n",
    "    rho_12: The initial correlation coefficient between surface 1 and surface 2\n",
    "    rho_13: The initial correlation coefficient between surface 1 and surface 3\n",
    "    rho_23: The initial correlation coefficient between surface 2 and surface 3\n",
    "    Return:\n",
    "    accuracy: The accuracy of the model for each surface\n",
    "    '''\n",
    "    to_use_winners = to_use[['winner1_name','winner2_name']]\n",
    "    to_use_losers = to_use[['loser1_name','loser2_name']]\n",
    "    to_use_surface = encode_marks(to_use['surface'])[0]\n",
    "    # 1. calculate rating \n",
    "    to_use_player_rating = calculate_ratings(winners= to_use_winners,\n",
    "                                             losers= to_use_losers,\n",
    "                                             surface= to_use_surface,\n",
    "                                             beta= beta,\n",
    "                                             variance_1=variance_1,\n",
    "                                             variance_2= variance_2,\n",
    "                                             variance_3=variance_3,\n",
    "                                             rho_12= rho_12,\n",
    "                                             rho_13= rho_13,\n",
    "                                             rho_23= rho_23)\n",
    "    correct = np.zeros((3,1))\n",
    "    total = np.zeros((3,1))\n",
    "    # 2. calculate the test accuracy \n",
    "    for game in np.arange(train.shape[0], to_use.shape[0]):\n",
    "        # get the current winners & losers\n",
    "        cur_winner_1 , cur_winner_2 = to_use_winners['winner1_name'][game], to_use_winners['winner2_name'][game]\n",
    "        cur_loser_1, cur_loser_2 = to_use_losers['loser1_name'][game], to_use_losers['loser2_name'][game]\n",
    "        # get the current surface\n",
    "        cur_surface = to_use_surface[game]\n",
    "        # get the winner & loser rating\n",
    "        cur_player_rating = to_use_player_rating[0][game]\n",
    "        cur_winner_1_rating, cur_winner_2_rating = cur_player_rating[cur_winner_1], cur_player_rating[cur_winner_2]\n",
    "        cur_loser_1_rating, cur_loser_2_rating = cur_player_rating[cur_loser_1], cur_player_rating[cur_loser_2]\n",
    "        # get the team rating\n",
    "        winner_team = cur_winner_1_rating + cur_winner_2_rating\n",
    "        loser_team = cur_loser_1_rating + cur_loser_2_rating\n",
    "        # get the surface\n",
    "        winner_surface = cur_surface.reshape((1,3)).dot(winner_team)\n",
    "        loser_surface = cur_surface.reshape((1,3)).dot(loser_team)\n",
    "        # check whether winner > loser\n",
    "        if winner_surface> loser_surface:\n",
    "            correct += cur_surface.reshape((3,1))\n",
    "        total += cur_surface.reshape((3,1))\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_my_accuracy = each_surface_accuracy(Train, \n",
    "                               to_use, \n",
    "                               3**2, \n",
    "                               train_parameter[1]['variance_1'], \n",
    "                               train_parameter[1]['variance_2'], \n",
    "                               train_parameter[1]['variance_3'], \n",
    "                               train_parameter[1]['rho_12'], \n",
    "                               train_parameter[1]['rho_13'],\n",
    "                               train_parameter[1]['rho_23'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy in clay = 61.7992%; The accuracy in grass = 65.8824%; The accuracy in hard = 63.4563%\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy in clay = {:.4f}%; The accuracy in grass = {:.4f}%; The accuracy in hard = {:.4f}%'.format(each_my_accuracy[0][0]*100,\n",
    "                                                                                                   each_my_accuracy[1][0]*100,\n",
    "                                                                                                   each_my_accuracy[2][0]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Loglikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(team\\  i\\  beats\\  \\  q\\  in\\  surface\\  k)  = \\left(\\dfrac{e^{\\theta_{ik}/c_{ijk}}}{e^{\\theta_{ik}/c_{ijk}} + e^{\\theta_{qk}/c_{ijk}}}\\right)^{s_{iqk}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$likelihood = \\prod f_{iqk}(z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$loglikelihood = log(likelihood)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surface_meanloglikelihood(train, to_use, beta, variance_1, variance_2, variance_3, rho_12, rho_13, rho_23):\n",
    "    '''\n",
    "    Args:\n",
    "    train: training dataset\n",
    "    to_use: total dataset\n",
    "    surface: The array of surfaces for each of N contest, of shape [N, 3]\n",
    "    beta: The uncontral variances of the game\n",
    "    variance_1: The initial variance of surface 1\n",
    "    variance_2: The initial variance of surface 2\n",
    "    variance_3: The initial variance of surface 3\n",
    "    rho_12: The initial correlation coefficient between surface 1 and surface 2\n",
    "    rho_13: The initial correlation coefficient between surface 1 and surface 3\n",
    "    rho_23: The initial correlation coefficient between surface 2 and surface 3\n",
    "    Return:\n",
    "    mean_loglikelihood: the loglikelihood\n",
    "    '''\n",
    "    to_use_winners = to_use[['winner1_name','winner2_name']]\n",
    "    to_use_losers = to_use[['loser1_name','loser2_name']]\n",
    "    to_use_surface = encode_marks(to_use['surface'])[0]\n",
    "    # 1. calculate rating \n",
    "    to_use_player_rating = calculate_ratings(winners= to_use_winners,\n",
    "                                             losers= to_use_losers,\n",
    "                                             surface= to_use_surface,\n",
    "                                             beta= beta,\n",
    "                                             variance_1=variance_1,\n",
    "                                             variance_2= variance_2,\n",
    "                                             variance_3=variance_3,\n",
    "                                             rho_12= rho_12,\n",
    "                                             rho_13= rho_13,\n",
    "                                             rho_23= rho_23)\n",
    "    surface_variance = np.array([[variance_1, rho_12 * np.sqrt(variance_1*variance_2), rho_13 * np.sqrt(variance_1*variance_3)],\n",
    "                                [rho_12 * np.sqrt(variance_1*variance_2), variance_2, rho_23 * np.sqrt(variance_2*variance_3)],\n",
    "                                [rho_13 * np.sqrt(variance_1*variance_3), rho_23 * np.sqrt(variance_2*variance_3), variance_3]])\n",
    "    \n",
    "    loglikelihood = 0 \n",
    "    total = 0\n",
    "    # 2. calculate the test loglikelihood \n",
    "    for game in np.arange(train.shape[0], to_use.shape[0]):\n",
    "        # get the current winners & losers\n",
    "        cur_winner_1 , cur_winner_2 = to_use_winners['winner1_name'][game], to_use_winners['winner2_name'][game]\n",
    "        cur_loser_1, cur_loser_2 = to_use_losers['loser1_name'][game], to_use_losers['loser2_name'][game]\n",
    "        # get the current surface\n",
    "        cur_surface = to_use_surface[game]\n",
    "        # get the winner & loser rating\n",
    "        cur_player_rating = to_use_player_rating[0][game]\n",
    "        cur_winner_1_rating, cur_winner_2_rating = cur_player_rating[cur_winner_1], cur_player_rating[cur_winner_2]\n",
    "        cur_loser_1_rating, cur_loser_2_rating = cur_player_rating[cur_loser_1], cur_player_rating[cur_loser_2]\n",
    "        # get the team rating\n",
    "        winner_team = cur_winner_1_rating + cur_winner_2_rating\n",
    "        loser_team = cur_loser_1_rating + cur_loser_2_rating\n",
    "        # get the surface\n",
    "        winner_surface = cur_surface.reshape((1,3)).dot(winner_team)[0][0]\n",
    "        loser_surface = cur_surface.reshape((1,3)).dot(loser_team)[0][0]\n",
    "        # c_ijk\n",
    "        sigma_k = cur_surface.reshape((1,3)).dot(surface_variance).dot(cur_surface.reshape((3,1)))[0]\n",
    "        c_ijk = np.sqrt(2*beta + sigma_k*2)[0]\n",
    "        # loglikelihood\n",
    "        data_i_likelihood = mp.log(mp.exp(winner_surface/c_ijk)/(mp.exp(winner_surface/c_ijk)+mp.exp(loser_surface/c_ijk)))\n",
    "        loglikelihood += data_i_likelihood\n",
    "        total+= 1\n",
    "    meanloglikelihood = loglikelihood / total\n",
    "    return meanloglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_meanloglikelihood = surface_meanloglikelihood(Train, \n",
    "                               to_use, \n",
    "                               3**2, \n",
    "                               train_parameter[1]['variance_1'], \n",
    "                               train_parameter[1]['variance_2'], \n",
    "                               train_parameter[1]['variance_3'], \n",
    "                               train_parameter[1]['rho_12'], \n",
    "                               train_parameter[1]['rho_13'],\n",
    "                               train_parameter[1]['rho_23'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean log-likelihood of model = -0.669215214532901\n"
     ]
    }
   ],
   "source": [
    "print('The Mean log-likelihood of model = {}'.format(my_meanloglikelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 結論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bradley - Terry model 轉換至 Elo model的過程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\dfrac{e^{\\theta_i/c_k}}{e^{\\theta_i/c_k}+e^{\\theta_j/c_k}}= \\dfrac{1}{1+e^{-(\\theta_i-\\theta_j)/c_k}}=\\dfrac{1}{1+10^{-(\\theta_i-\\theta_j)/(c_k*ln10)}}=\\dfrac{1}{1+10^{-\\dfrac{400(\\theta_i-\\theta_j)/(c_k*ln10)}{400}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 在Elo模型中，選手實力的初始值為1500，但在Bradley-Terry模型是否仍要設為1500或是其對應的數值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "準確度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model accuracy = 63.282769350447296 %\n"
     ]
    }
   ],
   "source": [
    "print('The model accuracy = {} %'.format(my_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean log-likelihoode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean log-likelihood of model = -0.669215214532901\n"
     ]
    }
   ],
   "source": [
    "print('The Mean log-likelihood of model = {}'.format(my_meanloglikelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Clay</th>\n",
       "      <th>Grass</th>\n",
       "      <th>Hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Clay</th>\n",
       "      <td>41.004494</td>\n",
       "      <td>58.595101</td>\n",
       "      <td>32.316773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grass</th>\n",
       "      <td>58.595101</td>\n",
       "      <td>250.371527</td>\n",
       "      <td>76.223515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hard</th>\n",
       "      <td>32.316773</td>\n",
       "      <td>76.223515</td>\n",
       "      <td>29.791092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Clay       Grass       Hard\n",
       "Clay   41.004494   58.595101  32.316773\n",
       "Grass  58.595101  250.371527  76.223515\n",
       "Hard   32.316773   76.223515  29.791092"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance_mat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "362.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
